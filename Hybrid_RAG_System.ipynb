{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16012840",
   "metadata": {
    "id": "16012840"
   },
   "source": [
    "# **HYBRID RAG SYSTEM for Sparse Municipal Environments:**\n",
    "This is the base code for our thesis, we're doing everything below, data preparing, embeddings, knowledge graph connections, running the hybrid system and testing the Hybrid RAG system performance via answering the competency questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zo9EFvmECnbm",
   "metadata": {
    "id": "Zo9EFvmECnbm"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/berkantcnr/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource/archive/refs/heads/master.zip -O /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-main.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lzwELKiMDBn9",
   "metadata": {
    "id": "lzwELKiMDBn9"
   },
   "outputs": [],
   "source": [
    "# unzip zip file\n",
    "!unzip /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-main.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Sx-wVvYO-9gW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sx-wVvYO-9gW",
    "outputId": "61a393ba-6a1f-43a2-c066-834937589bbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6855b04",
   "metadata": {
    "collapsed": true,
    "id": "c6855b04"
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a178b7fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a178b7fe",
    "outputId": "ac598f4b-c101-4fd1-d42a-8625814dc7df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      " ROOT_DIR: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master\n",
      " PDF Path: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs\n",
      " Font Path: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/assets/Roboto-Regular.ttf\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SETUP\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "ROOT_DIR = os.path.abspath(os.path.join(current_dir, '.'))\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"data\", \"municipal_pdfs\")\n",
    "ASSETS_DIR = os.path.join(ROOT_DIR, \"assets\")\n",
    "FONT_PATH = os.path.join(ASSETS_DIR, \"Roboto-Regular.ttf\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\" ROOT_DIR: {ROOT_DIR}\")\n",
    "print(f\" PDF Path: {DATA_PATH}\")\n",
    "print(f\" Font Path: {FONT_PATH}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982070ad",
   "metadata": {
    "id": "982070ad"
   },
   "source": [
    "# **DATA PREPARATION PART: **\n",
    "In municipal  domains, data is mostly unstructured and sparsed across various web portals. To address this lack of structured datasets and working effective indexing within our Vector Database, a custom data  pipeline was established.\n",
    "\n",
    "The source has 14 primary institutional websites (Parent Links). A recursive web scraping algorithm was developed to traverse these domains and their associated sub-pages, resulting in a total of 53 processed URLs.\n",
    "\n",
    "Data extraction was executed using the **BeautifulSoup4** library. A rigorous data cleaning phase followed, aimed at removing noise and unnecessary web elements—such as cookie consent banners, social media widgets, and navigation to ensure high-quality textual input.\n",
    "\n",
    "The cleaned data was subsequently converted into standardized PDF documents using the implementation provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08ebc0",
   "metadata": {
    "id": "4c08ebc0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# DATA INGESTION & PDF GENERATION\n",
    "# Scrapes target municipal websites, cleans the textual content,\n",
    "# and converts structured data into standardized PDF documents for RAG ingestion.\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "from fpdf import FPDF\n",
    "\n",
    "CONFIGURATION & PATHS\n",
    "# Paths are derived dynamically from the ROOT_DIR set in the previous cell.\n",
    "# If ROOT_DIR is not defined, we calculate it relative to this notebook.\n",
    "if 'ROOT_DIR' not in locals():\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
    "\n",
    "PDF_STORAGE_PATH = os.path.join(ROOT_DIR, \"data\", \"municipal_pdfs\")\n",
    "ASSETS_DIR = os.path.join(ROOT_DIR, \"assets\")\n",
    "FONT_PATH = os.path.join(ASSETS_DIR, \"Roboto-Regular.ttf\")\n",
    "\n",
    "# check directories exist\n",
    "os.makedirs(PDF_STORAGE_PATH, exist_ok=True)\n",
    "os.makedirs(ASSETS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# TARGET URLs \n",
    "\n",
    "TARGETS = [\n",
    "    # --- DIVERSITY MEDIA ---\n",
    "    {\"name\": \"DIVERSITY_MEDIA\", \"url\": \"https://diversitymedia.info/media-workspace\"},\n",
    "    {\"name\": \"DIVERSITY_MEDIA\", \"url\": \"https://diversitymedia.info/orga\"},\n",
    "    {\"name\": \"DIVERSITY_MEDIA\", \"url\": \"https://diversitymedia.info/kontakt\"},\n",
    "\n",
    "    # --- KUNSTKULTURQUARTIER ---\n",
    "    {\"name\": \"KUNSTKULTUR\", \"url\": \"https://www.kunstkulturquartier.de/werkstaetten\"},\n",
    "    {\"name\": \"KUNSTKULTUR\", \"url\": \"https://www.kunstkulturquartier.de/kuenstlerhaus/haus/kontakt-1\"},\n",
    "\n",
    "    # --- HEIZHAUS ---\n",
    "    {\"name\": \"HEIZHAUS\", \"url\": \"https://www.heizhaus.org/das-haus\"},\n",
    "    {\"name\": \"HEIZHAUS\", \"url\": \"https://www.heizhaus.org/kontakt\"},\n",
    "    {\"name\": \"HEIZHAUS\", \"url\": \"https://www.heizhaus.org/\"},\n",
    "\n",
    "    # --- LEIHLA (Bluepingu) ---\n",
    "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/\"},\n",
    "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/nutzungsbedingungen/\"},\n",
    "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/cb_itemgallery/?itemcat=werkzeug-allgemein\"},\n",
    "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/cb_itemgallery/?itemcat=technik\"},\n",
    "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/cb_itemgallery/?itemcat=werkzeug-textil\"},\n",
    "\n",
    "    # --- ESSBARE STADT ---\n",
    "    {\"name\": \"ESSBARE_STADT\", \"url\": \"https://essbare-stadt-nuernberg.de/fair-share/\"},\n",
    "    {\"name\": \"ESSBARE_STADT\", \"url\": \"https://leihbar.bluepingu.de/leihkatalog_essbare_stadt/\"},\n",
    "    {\"name\": \"ESSBARE_STADT\", \"url\": \"https://essbare-stadt-nuernberg.de/#kontakt\"},\n",
    "\n",
    "    # --- FABLAB NÜRNBERG ---\n",
    "    {\"name\": \"FABLAB_NBG\", \"url\": \"https://fablab-nuernberg.de/\"},\n",
    "    {\"name\": \"FABLAB_NBG\", \"url\": \"https://fablab-nuernberg.de/ueber-uns/der-verein\"},\n",
    "    {\"name\": \"FABLAB_NBG\", \"url\": \"https://fablab-nuernberg.de/ueber-uns/raeumlichkeiten\"},\n",
    "    {\"name\": \"FABLAB_NBG\", \"url\": \"https://fablab-nuernberg.de/ueber-uns/geraete\"},\n",
    "\n",
    "    # --- HOLZWERKSTATT GOSTENHOF ---\n",
    "    {\"name\": \"HOLZWERKSTATT\", \"url\": \"http://holzwerkstatt-gostenhof.de/\"},\n",
    "    {\"name\": \"HOLZWERKSTATT\", \"url\": \"http://holzwerkstatt-gostenhof.de/maschinen/\"},\n",
    "    {\"name\": \"HOLZWERKSTATT\", \"url\": \"http://holzwerkstatt-gostenhof.de/mitgliedschaft/\"},\n",
    "    {\"name\": \"HOLZWERKSTATT\", \"url\": \"http://holzwerkstatt-gostenhof.de/faq/\"},\n",
    "\n",
    "    # --- LEONARDO ---\n",
    "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/\"},\n",
    "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/makerspace-werkstatt/\"},\n",
    "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/ar-vr-labor-studio/\"},\n",
    "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/miracl-soundlabor-tonstudio/\"},\n",
    "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/eventspace-co-working-space/\"},\n",
    "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/kontakt/\"},\n",
    "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/ueber-uns/\"},\n",
    "\n",
    "    # --- FABLAB NÜLAND ---\n",
    "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/\"},\n",
    "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/index.php/wir-ueber-uns\"},\n",
    "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/index.php/das-fablab\"},\n",
    "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/index.php/mach-mit\"},\n",
    "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/index.php/kontakt\"},\n",
    "\n",
    "    # --- KOLEO ---\n",
    "    {\"name\": \"KOLEO\", \"url\": \"https://www.iska-nuernberg.de/koleo/\"},\n",
    "    {\"name\": \"KOLEO\", \"url\": \"https://www.iska-nuernberg.de/koleo/kontakt.html\"},\n",
    "\n",
    "    # --- KLARA ---\n",
    "    {\"name\": \"KLARA\", \"url\": \"https://www.nuernberg.de/internet/nuernberg_engagiert/klara.html\"},\n",
    "\n",
    "    # --- OHM LAB ---\n",
    "    {\"name\": \"OHM_LAB\", \"url\": \"https://www.th-nuernberg.de/einrichtungen-gesamt/administration-und-service/lehr-und-kompetenzentwicklung/lehr-und-lernraeume/ohmlab-maker-und-coworking-space/\"},\n",
    "\n",
    "    # --- FABLAB FAU ---\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/lasercutter/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/3d-drucker/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/schneideplotter/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/zerspanung/cnc-fraese/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/zerspanung/cnc-drehbank/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/elektrowerkzeuge/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/handwerkzeuge/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/textilbearbeitung/naehmaschine/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/textilbearbeitung/stickmaschine/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/textilbearbeitung/textilpresse/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/multifunktionstisch/\"},\n",
    "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/kontakt/\"},\n",
    "\n",
    "    # --- ODL ---\n",
    "    {\"name\": \"ODL_TOLLWERK\", \"url\": \"https://odl-nbg.de/de/\"}\n",
    "]\n",
    "\n",
    "# Cleaning functions\n",
    "\n",
    "def get_junk_list():\n",
    "    \"\"\"Returns a list of keywords and phrases to exclude during scraping.\"\"\"\n",
    "    return [\n",
    "        # Navigation\n",
    "        \"home\", \"startseite\", \"menu\", \"menü\", \"hauptmenü\", \"untermenü\",\n",
    "        \"navigation\", \"breadcrumb\", \"you are here\", \"sie sind hier\",\n",
    "        \"suche\", \"search\", \"suchen\", \"lupe\", \"leiste öffnen\",\n",
    "        \"zum inhalt springen\", \"skip to content\", \"zur hauptnavigation\",\n",
    "        \"navigation ausklappen\", \"top of page\", \"bottom of page\",\n",
    "        # Footer & Legal\n",
    "        \"impressum\", \"datenschutz\", \"privacy\", \"disclaimer\", \"haftungsausschluss\",\n",
    "        \"agb\", \"nutzungsbedingungen\", \"copyright\", \"alle rechte vorbehalten\",\n",
    "        \"powered by\", \"theme by\", \"wordpress\", \"secured by miniorange\",\n",
    "        # Cookie Consent\n",
    "        \"gdpr\", \"cookie\", \"cookies\", \"unbedingt notwendige cookies\",\n",
    "        \"einstellungen speichern\", \"alle aktivieren\", \"deaktiviert\", \"aktiviert\",\n",
    "        \"cookie-informationen\", \"cookie-einstellungen\",\n",
    "        # Actions & Auth\n",
    "        \"login\", \"anmelden\", \"register\", \"registrieren\", \"logout\", \"abmelden\",\n",
    "        \"warenkorb\", \"cart\", \"kasse\", \"checkout\", \"mein konto\",\n",
    "        \"passwort vergessen\", \"remember me\", \"mehr erfahren\", \"weiterlesen\",\n",
    "        # Social Media\n",
    "        \"instagram\", \"facebook\", \"youtube\", \"twitter\", \"linkedin\", \"rss\", \"feed\",\n",
    "        \"envelope\", \"google+\", \"xing\",\n",
    "        # Accessibility\n",
    "        \"barrierefreiheit\", \"text vergrößern\", \"graustufen\", \"kontrast\",\n",
    "        \"hoher kontrast\", \"heller modus\", \"links unterstreichen\", \"lesbare schriftart\",\n",
    "        \"nach oben\", \"top\", \"reset\", \"text verkleinern\", \"schriftgröße\"\n",
    "    ]\n",
    "\n",
    "def clean_text(text, url):\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = []\n",
    "    junk_exact = get_junk_list()\n",
    "\n",
    "    # Specific sidebar content for FAU FabLab\n",
    "    fau_sidebar = [\n",
    "        \"was ist ein fablab\", \"wie werde ich fablab-betreuer:in?\", \"termine\",\n",
    "        \"ausstattung\", \"maschinen im überblick\", \"preise\", \"bilder\", \"projekte\",\n",
    "        \"projekte unserer besucher\", \"forschungs- und abschlussarbeiten\",\n",
    "        \"project group diybio - build your own biotech lab\", \"english\"\n",
    "    ]\n",
    "\n",
    "    for line in lines:\n",
    "        original = line.strip()\n",
    "        lower_line = original.lower()\n",
    "\n",
    "        if not original: continue\n",
    "        if lower_line in junk_exact: continue\n",
    "\n",
    "        # Fix specific glitch in Bluepingu/Leihla site\n",
    "        if \"leihla\" in url:\n",
    "            if re.search(r'\\d{10,}', original):\n",
    "                original = re.sub(r'\\d{10,}', ' ', original).strip()\n",
    "                lower_line = original.lower()\n",
    "                if not original or original in [\"Fürth\", \"Marktplatz\"]:\n",
    "                    continue\n",
    "\n",
    "        if re.match(r'^\\d+$', original): continue\n",
    "        if re.search(r'\\(PDF, \\d+ KB\\)', original): continue\n",
    "        if original.startswith(\"<\") and original.endswith(\">\"): continue\n",
    "        if \"cookie\" in lower_line and (\"verwend\" in lower_line or \"einstellung\" in lower_line): continue\n",
    "        if \"gdpr\" in lower_line: continue\n",
    "        if \"instagram.com\" in lower_line or \"facebook.com\" in lower_line: continue\n",
    "        if \"source:\" in lower_line: continue\n",
    "        if \"internetverbindung abgebrochen\" in lower_line: continue\n",
    "        if \"spambots geschützt\" in lower_line: continue\n",
    "        if \"fablab-nuernberg\" in url:\n",
    "            if any(x in lower_line for x in [\"openlab\", \"kidslab\", \"repaircafé\", \"textilelab\"]) and len(original) < 25:\n",
    "                continue\n",
    "        if \"fablab.fau\" in url:\n",
    "            if lower_line in fau_sidebar: continue\n",
    "            if len(original) < 40 and any(x in lower_line for x in [\"3d-drucker\", \"lasercutter\", \"schneideplotter\", \"elektronik\", \"textilbearbeitung\", \"zerspanung\"]):\n",
    "                # Context check: preserve if the page itself is about that topic\n",
    "                is_current_topic = False\n",
    "                if \"lasercutter\" in lower_line and \"lasercutter\" in url: is_current_topic = True\n",
    "                if \"3d-drucker\" in lower_line and \"3d-drucker\" in url: is_current_topic = True\n",
    "                if \"schneideplotter\" in lower_line and \"schneideplotter\" in url: is_current_topic = True\n",
    "                if \"elektronik\" in lower_line and \"elektro\" in url: is_current_topic = True\n",
    "                if \"textil\" in lower_line and \"textil\" in url: is_current_topic = True\n",
    "                if \"zerspanung\" in lower_line and \"zerspanung\" in url: is_current_topic = True\n",
    "\n",
    "                if not is_current_topic:\n",
    "                    continue\n",
    "\n",
    "        cleaned_lines.append(original)\n",
    "\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def get_soup(url):\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.content, 'html.parser')\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Network issue with {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_pdf(text, url, filename):\n",
    "\n",
    "    # check font exists, download if necessary\n",
    "    if not os.path.exists(FONT_PATH):\n",
    "        print(f\"Roboto font not found at {FONT_PATH}. Downloading...\")\n",
    "        font_url = \"https://github.com/google/fonts/raw/main/ofl/roboto/Roboto-Regular.ttf\"\n",
    "        r = requests.get(font_url, allow_redirects=True)\n",
    "        with open(FONT_PATH, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(\"Font downloaded.\")\n",
    "\n",
    "    try:\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "        pdf.add_font('Roboto', '', FONT_PATH)\n",
    "        pdf.set_font('Roboto', '', 8)\n",
    "        pdf.set_text_color(100, 100, 100)\n",
    "        pdf.cell(0, 10, f\"Source: {url}\", new_x=\"LMARGIN\", new_y=\"NEXT\") # Updated for FPDF2\n",
    "        pdf.ln(5)\n",
    "        pdf.set_font('Roboto', '', 11)\n",
    "        pdf.set_text_color(0, 0, 0)\n",
    "\n",
    "        # Safe encode/decode to handle non-latin characters roughly\n",
    "        safe_text = text.encode('utf-8', 'replace').decode('utf-8')\n",
    "        pdf.multi_cell(0, 6, safe_text)\n",
    "        pdf.output(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to generate PDF for {url}: {e}\")\n",
    "\n",
    "# EXECUTION PIPELINE\n",
    "def execute_data_ingestion():\n",
    "    print(f\"Saving PDFs to: {PDF_STORAGE_PATH}\")\n",
    "\n",
    "    # Clean up existing PDF directory to ensure fresh data\n",
    "    if os.path.exists(PDF_STORAGE_PATH):\n",
    "        shutil.rmtree(PDF_STORAGE_PATH)\n",
    "    os.makedirs(PDF_STORAGE_PATH)\n",
    "\n",
    "    processed_urls = set()\n",
    "    count = 0\n",
    "\n",
    "    # Expand targets dynamically (e.g., Essbare Stadt catalogs)\n",
    "    expanded_targets = list(TARGETS)\n",
    "    for item in TARGETS:\n",
    "        if \"leihkatalog_essbare_stadt\" in item['url']:\n",
    "            print(\"Expanding Essbare Stadt Catalog...\")\n",
    "            soup = get_soup(item['url'])\n",
    "            if soup:\n",
    "                for a in soup.find_all('a', href=True):\n",
    "                    href = a['href']\n",
    "                    if \"itemcat\" in href:\n",
    "                        full_url = urljoin(item['url'], href)\n",
    "                        expanded_targets.append({\"name\": \"ESSBARE_STADT\", \"url\": full_url})\n",
    "\n",
    "    # Process all targets\n",
    "    for item in expanded_targets:\n",
    "        url = item['url']\n",
    "        institute_name = item['name']\n",
    "        base_url = url.split('#')[0]\n",
    "\n",
    "        if base_url in processed_urls: continue\n",
    "\n",
    "        print(f\"{institute_name}: {url}\")\n",
    "        soup = get_soup(url)\n",
    "        if not soup: continue\n",
    "\n",
    "        raw_text = soup.get_text()\n",
    "        final_text = clean_text(raw_text, url)\n",
    "\n",
    "        if len(final_text) < 20:\n",
    "            print(\"Content too short (possibly empty or protected).\")\n",
    "            continue\n",
    "\n",
    "        # Create safe filename\n",
    "        path_slug = urlparse(url).path.strip(\"/\").replace(\"/\", \"_\") or \"main\"\n",
    "        query_slug = urlparse(url).query.replace(\"=\", \"-\").replace(\"&\", \"_\")\n",
    "        safe_slug = f\"{path_slug}_{query_slug}\".strip(\"_\")\n",
    "        if not safe_slug: safe_slug = \"main\"\n",
    "\n",
    "        full_name = f\"{institute_name}_{safe_slug}\"[:60]\n",
    "        filename = os.path.join(PDF_STORAGE_PATH, f\"{full_name}.pdf\")\n",
    "\n",
    "        create_pdf(final_text, url, filename)\n",
    "        processed_urls.add(base_url)\n",
    "        count += 1\n",
    "        time.sleep(0.5) # Polite delay\n",
    "\n",
    "    print(f\"\\nFinished. Created {count} PDFs in {PDF_STORAGE_PATH}\")\n",
    "\n",
    "# Run the pipeline\n",
    "# Note: Since we already have the PDFs in './municipal_pdfs',\n",
    "# you can remove comment below out if you don't want to re-scrape.\n",
    "# execute_data_ingestion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e6ac1",
   "metadata": {
    "id": "f00e6ac1"
   },
   "source": [
    "Web scraping and data cleaning completed, pdfs created and ready in the path: /data/municipal_pdfs\n",
    "\n",
    "\n",
    "After creation of the PDFs, next step is create embeddings for Vector DB and KG and metadata tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22eab94d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3acadbc50bc9421abc71ca466f4c45d9",
      "e96665c4bfdf45dd9f5294f9dd485108",
      "cc75903d2fd94342ba09fe6e6f47c425",
      "674ee90c482444d7894b6a6f375a1628",
      "8c951d307d6e41af913da10cce22c3f1",
      "e0c72c5fc8df4501990fd60768bdd125",
      "22976fc8b32f468581f5e613e789615c",
      "eeae2fbaaf3140879c57151e2dd88bdb",
      "5c6f865e138e47abb3c052cd284248b3",
      "c8bf4520dfb347239135469216cdaf59",
      "4db8c644dc444131b324eaa2e8d75127",
      "ba1e8399034c41c5ac811073d6a4348e",
      "5b82e3f3129a4aeda96248f1afaf1ddf",
      "ebad2ee45f2742cc853999b350cc9598",
      "6a54cd98a9f1422cb55579f309d69508",
      "71f2ac27e267425faf6aa8fc52f192a1",
      "9960bdf19940428084f402212dc76dcb",
      "a9498aafe50a408f81179012d73206bd",
      "c30a619496ff404ea7f366c1569202cb",
      "409de6c9db0c410993ff29d566b513af",
      "690b2ec4e96043f4835f37e75df700b1",
      "d8e1094a8555494b8b8574ec4b949bac",
      "756b3816fc2e40e4b339bbd6ba2990bd",
      "aaf393d5b76d4ba280952ffa729b0948",
      "5b249b1f5570443cb44941f628e59ecc",
      "ad98ca8f24be479ea006336999804873",
      "5c70dda26cc94cb087a95d6650fe9abe",
      "de8918ae235c44888d07cfe4521a1449",
      "a77e7c92f46a46899d01d214caeeb0ee",
      "3339d13c60724390ab578ca442e1d895",
      "e60255ac64a84ebfa022cc558ed2bbed",
      "0cc59bf39bd64f4983167d41a1407800",
      "70d273a46a1d49d49086ba0d0e27ae81",
      "4a004ebb8e514c6883e699bb97ffaab9",
      "449723d9c5294d6dbbd30eb7569a4327",
      "b12ad7a0c5d94aaabb341c5378b8c877",
      "bda0cae086594198aef61e2be3b7e6c6",
      "36ff020813e4453e8b4060d9dc28d487",
      "f1c605d1bbdd4fa1894eab17384b4725",
      "d60e59f1b5764c348eb31b80ce0c2275",
      "84e64dc2032b479b89e63cb98239a69b",
      "12baca7c7e9144fc964cbf05ee5ea360",
      "d953d24909f349bc9cab8fa7bc385b7d",
      "6009ec7309954fdcbd0d081c70592fbf",
      "268b779eef274ddea90e33fbed520d7f",
      "0dfbe2d074e046c8b97eefbe20502a6d",
      "8a978ffcaa874899a9941e7166b8b8c2",
      "6b8f9f6d974d4de28103849c11457b19",
      "12160c8b08d6475a9f74be01aeccd5bd",
      "bdacb4c9a44449b4ae6b18736dbbb21e",
      "8e76fdad15af453785947e7d313882f7",
      "d03ba1c403964fb890f741b63e6f69ae",
      "9b66dcbfc9e240909bb4b65cefdfe270",
      "cfd9bb2972924e6294985010f900450b",
      "4ff2655e00784854b5ca9bb8ceeb3041",
      "4aa22801a8274dcea27c574a6dabc2ef",
      "fa65127ae09d495780f78cf5df4441bf",
      "7a6a893995504412acf83073c0717bcf",
      "ed89658a968f47558d2530301fb580b7",
      "797bb0bc13514e6283d6e7c11c33b72c",
      "6094e3b67b5044f0ae8e565d5fc049e3",
      "8fed908152a94f5b92e779c633e483c6",
      "9f48da33f9b145179c57ec9919fd155c",
      "77391ebdb62b4d51b76b83aef20a1cf2",
      "f467d48e96b9414b83add8bcab597342",
      "2070bf1146304bea9d8ffc8e758d5998",
      "a0d801600b6d40529d1d6417d5484c6e",
      "b71eacd23cda4466a1ebbe523f8fde70",
      "1d1063590da446dfac02a7e6c02179ff",
      "1da539a90feb4615959e36a9b17a59c2",
      "7f93087f36b14879bb8d95b277794e20",
      "2d06f0f832a246348e6ad2d5653f6072",
      "30b5cd2a0f62480385ffcb47f0d45ed8",
      "5a78e214491442a292147ca7fead258c",
      "64149230825641c09aa2b84abc14015c",
      "0f6d7307db59403faa7717fbece9bde0",
      "c9e4569d22f44153a044effb8d71548a",
      "be3e253dc6624a97a17f85f82aacbf68",
      "20ce10e14da0400caced5d8d7be01e84",
      "b8ebc1e6bed3403985154e0c68dbad25",
      "15f5dca76ebc43eda85ea4d7e60d1e49",
      "56024ba622b940e5bf19946a4b231fc4",
      "9801833b2bef4100bd348ccd41b2c30b",
      "c144b8e7a14747319fdd79a50c639f77",
      "e3d201d5f50c4cd993e8dc7d2e1e2b49",
      "53b147eca6064fb692ea80569e2705ff",
      "7a676b8a5e404b219e4a56adc94ba901",
      "87e8ab01be8a40f8b694f6be72cd64b7",
      "539fbfa3c5f34e0ea36435667470b9f6",
      "e8b7cd7858c44e1bbbd27ed554f0aba6",
      "fcd639c6e81a414ba63925b590af7e97",
      "265c42061b8b4fc497ff0b49eb759761",
      "ccc31853e12d433594283d5b1f2608c8",
      "d143e65ae1104e58ba5127ac7b7af7d7",
      "dca00ffb59ae474885cc8266e9a40bf0",
      "7d6b7dcceac747558284b69d721ae5e2",
      "d2191783adf94d64adcb739fae236ec2",
      "d84fcab549d64a95a9886368c88fe756",
      "53951dc1f0f64a6fa218d48446e0dfd1",
      "a5cfdd873ebf446483fd5d07250b450d",
      "077aa8456f604ae8a0831ed716624d60",
      "06269d9d5aac47029c8d46ed97312fff",
      "e5c99ce56e2841f39fc724700e709fdb",
      "70f5116f314f452fa0693384c875b6b1",
      "563c5c29980d47789acaeace17e8cbb8",
      "e1ed67d62e26406a837b0ad38c41444a",
      "114fb3c7c52143a8a4471c9dfd8b1eab",
      "e7c180cba0964e318514a57f40b70f99",
      "0bb3c7921a194915b4225093df20434b",
      "738a5d65fa2a4c2d8c17fbe983026363",
      "41caa037eb3a4d8b956d90a376844105",
      "b017cccfecce47c8aad6c94da7ddaeb6",
      "ca3aa4bbc9764eb8b4dc9680c06b93f9",
      "e14f3909925d46fabc3303aabc1aa81c",
      "6c9b7dddec0f4a7bb094ed19ddfd7e53",
      "e2dfca3fc38d446d828253d3d24a31bf",
      "e03114874aca4eceb7f1677b5dd6be9a",
      "21e6ae8f6b88483d828ab667fc98543a",
      "afee90d2385d4fa4ba23cae0bf886681",
      "e1506b75aa4345e08df4149b30f159ff",
      "cd7fff4db7174773ac1c92d47df629c9"
     ]
    },
    "id": "22eab94d",
    "outputId": "fbb7dc66-dfd9-4998-d7e4-af7f2d0f3660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Source: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs\n",
      "Vector DB Target: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db\n",
      " Deleted existing collection: municipal_pdfs_rag\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acadbc50bc9421abc71ca466f4c45d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1e8399034c41c5ac811073d6a4348e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756b3816fc2e40e4b339bbd6ba2990bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a004ebb8e514c6883e699bb97ffaab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268b779eef274ddea90e33fbed520d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa22801a8274dcea27c574a6dabc2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d801600b6d40529d1d6417d5484c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3e253dc6624a97a17f85f82aacbf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539fbfa3c5f34e0ea36435667470b9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cfdd873ebf446483fd5d07250b450d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41caa037eb3a4d8b956d90a376844105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 PDFs. Processing...\n",
      "Processed: DIVERSITY_MEDIA_kontakt.pdf\n",
      "Processed: DIVERSITY_MEDIA_media-workspace.pdf\n",
      "Processed: DIVERSITY_MEDIA_orga.pdf\n",
      "Processed: ESSBARE_STADT_fair-share.pdf\n",
      "Processed: ESSBARE_STADT_leihkatalog_essbare_stadt.pdf\n",
      "Processed: ESSBARE_STADT_main.pdf\n",
      "Processed: FABLAB_FAU_elektrowerkzeuge.pdf\n",
      "Processed: FABLAB_FAU_kontakt.pdf\n",
      "Processed: FABLAB_FAU_main.pdf\n",
      "Processed: FABLAB_FAU_tool_3d-drucker.pdf\n",
      "Processed: FABLAB_FAU_tool_handwerkzeuge.pdf\n",
      "Processed: FABLAB_FAU_tool_lasercutter.pdf\n",
      "Processed: FABLAB_FAU_tool_multifunktionstisch.pdf\n",
      "Processed: FABLAB_FAU_tool_schneideplotter.pdf\n",
      "Processed: FABLAB_FAU_tool_textilbearbeitung_naehmaschine.pdf\n",
      "Processed: FABLAB_FAU_tool_textilbearbeitung_stickmaschine.pdf\n",
      "Processed: FABLAB_FAU_tool_textilbearbeitung_textilpresse.pdf\n",
      "Processed: FABLAB_FAU_tool_zerspanung_cnc-drehbank.pdf\n",
      "Processed: FABLAB_FAU_tool_zerspanung_cnc-fraese.pdf\n",
      "Processed: FABLAB_NBG_main.pdf\n",
      "Processed: FABLAB_NBG_ueber-uns_der-verein.pdf\n",
      "Processed: FABLAB_NBG_ueber-uns_geraete.pdf\n",
      "Processed: FABLAB_NBG_ueber-uns_raeumlichkeiten.pdf\n",
      "Processed: FABLAB_NUELAND_index.php_das-fablab.pdf\n",
      "Processed: FABLAB_NUELAND_index.php_kontakt.pdf\n",
      "Processed: FABLAB_NUELAND_index.php_mach-mit.pdf\n",
      "Processed: FABLAB_NUELAND_index.php_wir-ueber-uns.pdf\n",
      "Processed: FABLAB_NUELAND_main.pdf\n",
      "Processed: HEIZHAUS_das-haus.pdf\n",
      "Processed: HEIZHAUS_kontakt.pdf\n",
      "Processed: HEIZHAUS_main.pdf\n",
      "Processed: HOLZWERKSTATT_faq.pdf\n",
      "Processed: HOLZWERKSTATT_main.pdf\n",
      "Processed: HOLZWERKSTATT_maschinen.pdf\n",
      "Processed: HOLZWERKSTATT_mitgliedschaft.pdf\n",
      "Processed: KLARA_internet_nuernberg_engagiert_klara.html.pdf\n",
      "Processed: KOLEO_koleo.pdf\n",
      "Processed: KOLEO_koleo_kontakt.html.pdf\n",
      "Processed: KUNSTKULTUR_kuenstlerhaus_haus_kontakt-1.pdf\n",
      "Processed: KUNSTKULTUR_werkstaetten.pdf\n",
      "Processed: LEIHLA_cb_itemgallery_itemcat-technik.pdf\n",
      "Processed: LEIHLA_cb_itemgallery_itemcat-werkzeug-allgemein.pdf\n",
      "Processed: LEIHLA_cb_itemgallery_itemcat-werkzeug-textil.pdf\n",
      "Processed: LEIHLA_main.pdf\n",
      "Processed: LEIHLA_nutzungsbedingungen.pdf\n",
      "Processed: LEONARDO_kontakt.pdf\n",
      "Processed: LEONARDO_labs.pdf\n",
      "Processed: LEONARDO_labs_ar-vr-labor-studio.pdf\n",
      "Processed: LEONARDO_labs_eventspace-co-working-space.pdf\n",
      "Processed: LEONARDO_labs_makerspace-werkstatt.pdf\n",
      "Processed: LEONARDO_labs_miracl-soundlabor-tonstudio.pdf\n",
      "Processed: LEONARDO_ueber-uns.pdf\n",
      "Processed: ODL_TOLLWERK_de.pdf\n",
      "Processed: OHM_LAB_einrichtungen-gesamt_administration-und-service_lehr.pdf\n",
      "Upserting 742 chunks into 'municipal_pdfs_rag'...\n",
      "Vector Database populated. Total chunks: 742\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# VECTOR DATABASE CREATION & PDF EMBEDDING\n",
    "\n",
    "# Reads processed PDFs, assigns Knowledge Graph entity tags (E74),\n",
    "# chunks the text, and creates embeddings in ChromaDB.\n",
    "#\n",
    "# CONFIGURATION NOTE:\n",
    "# This script is configured by default to use L2 (Euclidean) distance.\n",
    "# To use Cosine Similarity, uncomment the specific metadata configuration\n",
    "# in the 'Initialize Collection' section below.\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PATH CONFIGURATION\n",
    "\n",
    "if 'DATA_PATH' not in locals() or 'CHROMA_PATH' not in locals():\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
    "    DATA_PATH = os.path.join(ROOT_DIR, \"data\", \"municipal_pdfs\")\n",
    "    CHROMA_PATH = os.path.join(ROOT_DIR, \"chroma_db\")\n",
    "\n",
    "print(f\"PDF Source: {DATA_PATH}\")\n",
    "print(f\"Vector DB Target: {CHROMA_PATH}\")\n",
    "\n",
    "# ENTITY MAPPING (PDF FILENAME -> KNOWLEDGE GRAPH GROUP)\n",
    "\n",
    "PDF_TO_E74 = {\n",
    "    \"DIVERSITY_MEDIA\": \"Diversity_Media\",\n",
    "    \"ESSBARE_STADT\": \"essbare_Stadt_Nürnberg_e.V.\",\n",
    "    \"FABLAB_FAU\": \"FAU_FabLab\",\n",
    "    \"FABLAB_NBG\": \"FabLab_Nürnberg\",\n",
    "    \"FABLAB_NUELAND\": \"FabLab_Nüland\",\n",
    "    \"HEIZHAUS\": \"Heizhaus_Nürnberg\",\n",
    "    \"HOLZWERKSTATT\": \"Holzwerkstatt_Gostenhof_e.V.\",\n",
    "    \"KLARA\": \"KLARA\",\n",
    "    \"KOLEO\": \"KOLEO\",\n",
    "    \"KUNSTKULTUR\": \"KunstKultur_Quartier_Werkstatten\",\n",
    "    \"LEIHLA\": \"Leihla_Nürnberg\",\n",
    "    \"LEONARDO\": \"Leonardo_Zentrum\",\n",
    "    \"ODL_TOLLWERK\": \"tollwerk_GmbH\",\n",
    "    \"OHM_LAB\": \"TH_Nürnberg\",\n",
    "}\n",
    "\n",
    "def infer_e74_group(filename: str) -> str:\n",
    "    for prefix, e74 in PDF_TO_E74.items():\n",
    "        if filename.startswith(prefix + \"_\"):\n",
    "            return e74\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "# INITIALIZE CHROMA CLIENT & COLLECTION\n",
    "client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "# --- CONFIGURATION SWITCH ---\n",
    "# Option A: Standard L2 Distance (Default)\n",
    "COLLECTION_NAME = \"municipal_pdfs_rag\"\n",
    "\n",
    "# Option B: Cosine Similarity (Uncomment to use)\n",
    "# COLLECTION_NAME = \"municipal_pdfs_cosine\"\n",
    "\n",
    "try:\n",
    "    client.delete_collection(name=COLLECTION_NAME)\n",
    "    print(f\" Deleted existing collection: {COLLECTION_NAME}\")\n",
    "except:\n",
    "    print(f\" Collection {COLLECTION_NAME} did not exist. Creating new.\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Embedding Model\n",
    "class NormalizedEmbeddingFunction(chromadb.EmbeddingFunction):\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def __call__(self, input):\n",
    "        # normalize_embeddings\n",
    "        return self.model.encode(input, convert_to_numpy=True, normalize_embeddings=True).tolist()\n",
    "\n",
    "\n",
    "ef = NormalizedEmbeddingFunction(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "# Create Collection\n",
    "# ---------------------------------------------------------\n",
    "# OPTION A: Standard Creation (L2 Distance) - ACTIVE\n",
    "collection = client.create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=ef\n",
    ")\n",
    "\n",
    "# OPTION B: Cosine Similarity Configuration - INACTIVE\n",
    "# Uncomment the block below to enable Cosine Similarity\n",
    "# collection = client.create_collection(\n",
    "#     name=COLLECTION_NAME,\n",
    "#     embedding_function=ef,\n",
    "#     metadata={\"hnsw:space\": \"cosine\"} # Critical for Cosine Similarity\n",
    "# )\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "# CHUNKING CONFIGURATION\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# EXECUTION: PROCESS & EMBED\n",
    "\n",
    "def build_vector_database():\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(f\"[ERROR] PDF directory not found: {DATA_PATH}\")\n",
    "        return\n",
    "\n",
    "    pdf_files = [f for f in os.listdir(DATA_PATH) if f.endswith(\".pdf\")]\n",
    "    print(f\"Found {len(pdf_files)} PDFs. Processing...\")\n",
    "\n",
    "    all_chunks, all_metas, all_ids = [], [], []\n",
    "\n",
    "    for filename in sorted(pdf_files):\n",
    "        file_path = os.path.join(DATA_PATH, filename)\n",
    "        try:\n",
    "            reader = PdfReader(file_path)\n",
    "            full_text = \"\\n\".join([p.extract_text() or \"\" for p in reader.pages])\n",
    "\n",
    "            if not full_text.strip():\n",
    "                print(f\"[ERROR] Skipping empty file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            chunks = text_splitter.split_text(full_text)\n",
    "            e74_group = infer_e74_group(filename)\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                all_chunks.append(chunk)\n",
    "                all_metas.append({\n",
    "                    \"source_pdf\": filename,\n",
    "                    \"e74_group\": e74_group,\n",
    "                    \"chunk_index\": i\n",
    "                })\n",
    "                all_ids.append(f\"{filename}_chunk_{i}\")\n",
    "\n",
    "            print(f\"Processed: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process {filename}: {e}\")\n",
    "\n",
    "    # Upsert to DB\n",
    "    if all_chunks:\n",
    "        print(f\"Upserting {len(all_chunks)} chunks into '{COLLECTION_NAME}'...\")\n",
    "\n",
    "        batch_size = 5000\n",
    "        for i in range(0, len(all_chunks), batch_size):\n",
    "            end = min(i + batch_size, len(all_chunks))\n",
    "            collection.upsert(\n",
    "                documents=all_chunks[i:end],\n",
    "                metadatas=all_metas[i:end],\n",
    "                ids=all_ids[i:end]\n",
    "            )\n",
    "\n",
    "        print(f\"Vector Database populated. Total chunks: {collection.count()}\")\n",
    "    else:\n",
    "        print(\"[ERROR] No chunks found to insert.\")\n",
    "\n",
    "# Uncomment to run the build process. pdfs already processed and provided.\n",
    "#build_vector_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc4b0cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543,
     "referenced_widgets": [
      "b45e8578bf404c449fb5df017ec0c00d",
      "958459cb7ce4461596d82c860695c265",
      "1abd7cd5673c4c7bbb0aec545ec2a6c9",
      "e8fec536c7624709a41fd77403074468",
      "e271057e54664395a40e83f930faf471",
      "29ca25b9152c473fa9fc67a0a4937767",
      "51e01da2f5554588800767f740974bec",
      "04b409bfa2444b1aa8dc42a675fc3a85",
      "f4008ece621e4ee1bfeb4f97d1e2e2f7",
      "60f78df4966344de89bef0a8c96572c0",
      "285edb657206467da6a0f404740bbbab",
      "5191ad13bd2a442985f5f3993bf3e99c",
      "bc169003ad0c4945848fde339c4b5a9f",
      "cee0bfe35301474ba36644768e58b09e",
      "39a6585c5c0844fd8c0fbd74d9cd3d44",
      "98c23518c33b4e8c98b63650e513ab37",
      "5eec62df89234143ac8f0a2f4d000fbd",
      "7d47650d7e54439c977407f1fb39257b",
      "e7b91b9d40214bcea55d5c212dc02ef3",
      "79bc3f73a3ff43f89ff9b9825be4f840",
      "ac123a90dd2b4b9abc0dc90e955bb15e",
      "4ae92868b62344c286f1bffd14f5be78",
      "1778e1a122b54fcb808f6e49cadbc9db",
      "70cd202a866a4d33a69b5dc9c8172b3e",
      "3166bd4e27e44e0987db32890fed36f6",
      "263ea28bec124357b4ca11c0f1c737d9",
      "92085c66f171475c8bb0c8f0b1388bd8",
      "45e7c153c10647638ea7f8b083390723",
      "360469ecefa04bcfb43b4fec0b05342b",
      "f3fe2baa65de41c2975cafe0601b0ccf",
      "7644976d28c04d58876c08a03547e39c",
      "0ea783a695de46b49e130668c18e9b46",
      "8114b06b1d154bbba0e4568351f9c73f",
      "74d037fd9b1f4e8bb6275a10158d46f7",
      "da99c84ea1704ae6a727855ef1ef541a",
      "d76c1cda6d7f4392a3bb44c9ff79253f",
      "92150b82231948a19a73e97d6032d392",
      "095643ab345145099e03740388edda7d",
      "81c7a4adf7a942a4a97f34271ba550d7",
      "baec243f5dc34d9eaa04264586f1a7ca",
      "a165a41aac61437393c3f020df0532c7",
      "5d02105945b64b03b26eceb0dadf1d27",
      "d275cf9fbca4418eb7151c90dc48279d",
      "0f9822ed23f8451b8c4fcf408be92800",
      "28e3c52b8bce4032a3f95380bd24a2c6",
      "ea9ff0b5e88b49818f4a56911e2f5759",
      "54db4351bfc34259894c772bc243a3af",
      "5cd3e1f4db8845ecb98dc51a3cdaa88a",
      "1d67b80a769941b6964054413ff3ffc3",
      "0b7520ada8d645bb9a3d8ca6746b5e73",
      "3dc0e83c4855409fb25fe22cf927a458",
      "e2cf5790ca1e4b1e9a25e069b21430d3",
      "ff9394efc6ab4fa895e5a84c9b08c633",
      "a44ead79ddfe48a0b4252cefbda58f13",
      "169dced5dcc540d6a9b61ea1eb7ddc17",
      "f44a6788bc0447f58d98f2fcf80c7339",
      "4bf9fa2545d5499991f2fe47668998e4",
      "560f4920bc784c8ca4666e6269b92cec",
      "c3cb87ab2d1d4f89a2c2f0b52306b4c3",
      "64bf86acb50a4408b82a7a2c90ed6983",
      "21c926143f854f00afdd877755ff992f",
      "fd90ba3f014a4a5cafb8283f52fa95b1",
      "a2a5b8c1e34841a2a080dd6b5ae80e41",
      "7588cba3848c4351b2547d7faa3f7b6d",
      "f77b0bdec6804889bb6fc946fd1d6e05",
      "c278fc58941c4e238562cdf5d9511b97",
      "02a89e3daa79433aa2eeda84d1b7e169",
      "22735c6d60924f3a8bd6d62179b44d90",
      "20e45f4d37354cd89ecd8cf5d75fdca8",
      "f448766bace54b16a76d2b01eeddd5e3",
      "a236e8c01e18450fabacd8ed4636d2b9",
      "6342b1707acf4c72901e4b33a2a7bd4f",
      "488e628370044bdc82284c8709337e0e",
      "e452672925824beeb10b52fec6c8edb2",
      "84f91cf2068f4e439a1ce8311741667a",
      "42b4cc44433a41d8a3329235e6fe8dc6",
      "f69ecfcc2a334019b7884aee643463c3",
      "882721463b5f471db07b95bd07615c20",
      "403a9752526f4ed1bcb1546b1e57fba0",
      "43de74a83d7e4aaa971d6c04c6cfca54",
      "8e83855a312c431f80451b64e45c81d6",
      "4d46ce23c5524c439176800b00e0eeb4",
      "ad196f33de324021a41d06e4d75eab38",
      "5d6cfb68444f4240b88dfda712605976",
      "31e7d62f42dc4e97a2e443ca89ec29ca",
      "6352ce6cfc724435bfe5c3eca6e42288",
      "9c4ce19e41b54776bf271cd7871cf04d",
      "d9af3f79adb94d038f1658585bdb86bb",
      "76830901fc5744debb5fb9e0790ac178",
      "80dded1a3cce4cc280f3ef8a9ed49d7c",
      "8c9b00f3adde4d25a3aa5b9dd4cfd5dc",
      "7ad28425b16047e58cb91718dea360c3",
      "2b49184508a64058b1bba95cd488368a",
      "3d8ac5d347094d9e824d5aa725dbdb48",
      "b82a31db278a4ee990ab90f779c16cb0",
      "37394dd3a66442ba8508c37d51728f32",
      "72828821e0ca4010b87357dbe4dd9746",
      "f20d58d9af3242a5a5be3b4d7a964fe2",
      "ae5e3b894e784bbe9fd7348784655fde",
      "6e9ffbe41f0b473a933fb43bca7219dc",
      "66e680e9738d40eda5734f84cc7776ac",
      "eaa64fd024a649ff98d99973df0fe752",
      "654ea28b2e4a4aebb6e0b707c1568538",
      "4d67337111c6456796dd7203985bf381",
      "2f2de818e19447c685e3cd4abd8440ed",
      "e6d15ae5cc584d25be75092d1b6aaa11",
      "1e84af1d18634a238f789eeb6edb8555",
      "8bbc3bbd34b349f5b8f7b3cd33b487eb",
      "9f7a7cb083824c48af9e30467826540e",
      "965de5e1cc3e4c84be71a7d480e1b243",
      "c37930b66c60437a8a022ba9367b34b9",
      "04d77a6e13ae455d9e4d2d51f963ae92",
      "d877ed8119394ab98630a3ef5c7e2ef8",
      "eedd8ad9a9ab4c32a16d139af7b4524c",
      "80947d227ec24ca5902424ce85ab6464",
      "061f71227e294f4495cea34f31aa0e2a",
      "a87b18251b594a44b79022c9f319e99b",
      "32e8466ccf5041dba93e4d265d5f1a48",
      "e1e40c5630b44fb5a7fbbfa75b939ce9",
      "b28fb0c877334f6fb7bcfd6cf5c4c6c7",
      "967826f3bf104223912f6a6ffe922432"
     ]
    },
    "id": "efc4b0cb",
    "outputId": "225330f3-2b4a-48a1-bd88-f08c6d76cdad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG Vector DB Target: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db\n",
      "Embedding Model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Connecting to Neo4j at neo4j+s://be24de9e.databases.neo4j.io...\n",
      "Connected to Neo4j.\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45e8578bf404c449fb5df017ec0c00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5191ad13bd2a442985f5f3993bf3e99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1778e1a122b54fcb808f6e49cadbc9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d037fd9b1f4e8bb6275a10158d46f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e3c52b8bce4032a3f95380bd24a2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44a6788bc0447f58d98f2fcf80c7339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a89e3daa79433aa2eeda84d1b7e169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882721463b5f471db07b95bd07615c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76830901fc5744debb5fb9e0790ac178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9ffbe41f0b473a933fb43bca7219dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37930b66c60437a8a022ba9367b34b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection: kg_structural_rag\n",
      "Fetching data from Neo4j and serializing...\n",
      "Ingesting 890 vectors into ChromaDB...\n",
      "Knowledge Graph Embedding Complete.\n",
      "Total Records in 'kg_structural_rag': 890\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNOWLEDGE GRAPH EMBEDDING (SERIALIZATION)\n",
    "# Connects to Neo4j, serializes nodes and relationships into\n",
    "# natural language text (Structural Embedding), and stores them in a\n",
    "# separate ChromaDB collection with CRITICAL METADATA.\n",
    "#\n",
    "# CONFIGURATION NOTE:\n",
    "# This script is configured by default to use L2 (Euclidean) distance.\n",
    "# To use Cosine Similarity, uncomment the specific metadata configuration\n",
    "# in the 'Initialize Collection' section below.\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. CONFIGURATION & CREDENTIALS\n",
    "if 'CHROMA_PATH' not in locals():\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
    "    CHROMA_PATH = os.path.join(ROOT_DIR, \"chroma_db\")\n",
    "\n",
    "load_dotenv()\n",
    "# Neo4j Credentials (Securely loaded from .env)\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "if not NEO4J_URI or not NEO4J_PASSWORD:\n",
    "    raise ValueError(\"[ERROR] Neo4j credentials missing in .env file.\")\n",
    "\n",
    "# Option A: Standard L2 Distance (Default)\n",
    "COLLECTION_NAME = \"kg_structural_rag\"\n",
    "\n",
    "# Option B: Cosine Similarity (Uncomment to use and comment other option)\n",
    "# COLLECTION_NAME = \"kg_structural_cosine\"\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "print(f\"KG Vector DB Target: {CHROMA_PATH}\")\n",
    "print(f\"Embedding Model: {MODEL_NAME}\")\n",
    "\n",
    "\n",
    "# HELPER CLASSES AND FUNCTIONS\n",
    "\n",
    "\n",
    "class StructuralEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, model_name):\n",
    "        print(f\"Loading embedding model: {model_name}...\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        return self.model.encode(input, convert_to_numpy=True, normalize_embeddings=True).tolist()\n",
    "\n",
    "def safe_str(value):\n",
    "    if isinstance(value, list):\n",
    "        return \", \".join(str(v) for v in value)\n",
    "    return str(value)\n",
    "\n",
    "def get_node_name(node):\n",
    "    props = dict(node)\n",
    "    return props.get('name', props.get('title', node.element_id))\n",
    "\n",
    "# MAIN PIPELINE\n",
    "\n",
    "\n",
    "def generate_kg_embeddings():\n",
    "    # 1. Initialize Connections\n",
    "    print(f\"Connecting to Neo4j at {NEO4J_URI}...\")\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "        driver.verify_connectivity()\n",
    "        print(\"Connected to Neo4j.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Connection Failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize ChromaDB\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "    embedding_func = StructuralEmbeddingFunction(MODEL_NAME)\n",
    "\n",
    "    # 2. Reset Collection\n",
    "    try:\n",
    "        chroma_client.delete_collection(name=COLLECTION_NAME)\n",
    "        print(f\"Deleted existing collection: {COLLECTION_NAME}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Create Collection\n",
    "    # OPTION A: Standard Creation (L2 Distance) - ACTIVE\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        embedding_function=embedding_func\n",
    "    )\n",
    "\n",
    "    # OPTION B: Cosine Similarity Configuration - INACTIVE\n",
    "    # Uncomment the block below to enable Cosine Similarity\n",
    "    # collection = chroma_client.create_collection(\n",
    "    #     name=COLLECTION_NAME,\n",
    "    #     embedding_function=embedding_func,\n",
    "    #     metadata={\"hnsw:space\": \"cosine\"} # Critical for Cosine Similarity\n",
    "    # )\n",
    "    # ---------------------------------------------------------\n",
    "\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    print(\"Fetching data from Neo4j and serializing...\")\n",
    "\n",
    "    with driver.session() as session:\n",
    "\n",
    "        # PHASE A: PROCESS NODES (Entity Serialization)\n",
    "        result_nodes = session.run(\"MATCH (n) RETURN n\")\n",
    "\n",
    "        for record in result_nodes:\n",
    "            node = record[\"n\"]\n",
    "            props = dict(node)\n",
    "            labels = list(node.labels)\n",
    "            label_str = labels[0] if labels else \"Unknown Entity\"\n",
    "            name = get_node_name(node)\n",
    "\n",
    "            # 1. Text Serialization\n",
    "            text_rep = f\"Entity: {name}. Type: {label_str}.\"\n",
    "            for key, value in props.items():\n",
    "                if key not in ['name', 'title', 'uri', 'element_id']:\n",
    "                    if value:\n",
    "                        text_rep += f\" {key.replace('_', ' ')}: {value}.\"\n",
    "\n",
    "            # 2. Metadata (CRITICAL FOR HYBRID LINKING)\n",
    "            meta = {\n",
    "                \"kind\": \"entity\",\n",
    "                \"entity_name\": safe_str(name),\n",
    "                \"labels\": safe_str(label_str),\n",
    "                \"source\": \"neo4j\"\n",
    "            }\n",
    "\n",
    "            documents.append(text_rep)\n",
    "            metadatas.append(meta)\n",
    "            ids.append(f\"node_{node.element_id}\")\n",
    "\n",
    "        # PHASE B: PROCESS RELATIONSHIPS (Structural Sentences)\n",
    "        result_rels = session.run(\"MATCH (n)-[r]->(m) RETURN n, r, m\")\n",
    "\n",
    "        for record in result_rels:\n",
    "            source = record[\"n\"]\n",
    "            rel = record[\"r\"]\n",
    "            target = record[\"m\"]\n",
    "\n",
    "            s_name = get_node_name(source)\n",
    "            t_name = get_node_name(target)\n",
    "\n",
    "            # 1. Text Serialization\n",
    "            text_rep = f\"{s_name} is connected to {t_name} via relation {rel.type}.\"\n",
    "\n",
    "            # 2. Metadata (CRITICAL FOR GRAPH CONTEXT)\n",
    "            meta = {\n",
    "                \"kind\": \"relationship\",\n",
    "                \"source_node\": safe_str(s_name),\n",
    "                \"target_node\": safe_str(t_name),\n",
    "                \"relation_type\": safe_str(rel.type),\n",
    "                \"source\": \"neo4j\"\n",
    "            }\n",
    "\n",
    "            documents.append(text_rep)\n",
    "            metadatas.append(meta)\n",
    "            ids.append(f\"rel_{rel.element_id}\")\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    # Batch Ingestion\n",
    "    total_docs = len(documents)\n",
    "    if total_docs > 0:\n",
    "        print(f\"Ingesting {total_docs} vectors into ChromaDB...\")\n",
    "        batch_size = 500\n",
    "\n",
    "        for i in range(0, total_docs, batch_size):\n",
    "            end_idx = min(i + batch_size, total_docs)\n",
    "            collection.add(\n",
    "                documents=documents[i:end_idx],\n",
    "                metadatas=metadatas[i:end_idx],\n",
    "                ids=ids[i:end_idx]\n",
    "            )\n",
    "\n",
    "        print(\"Knowledge Graph Embedding Complete.\")\n",
    "        print(f\"Total Records in '{COLLECTION_NAME}': {collection.count()}\")\n",
    "    else:\n",
    "        print(\"[ERROR] No data found to process.\")\n",
    "\n",
    "# Uncomment to run the build process because kg embeddings are also provided in chroma db folder.\n",
    "#generate_kg_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6d1af3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595,
     "referenced_widgets": [
      "4d0b95c1641c44be8ba7903db0eaaec4",
      "b8b14509f3164de6a46414a9e08d5d27",
      "1167bc194179400fbf960dfe501629eb",
      "6ce1be72b5d74bf7892fc537c1597a1d",
      "2e9039eaef2e4fa98bd3a3e1d2ac3cf4",
      "9d0eef5947d846659ca218b277d8d762",
      "5394c33ccbcf40ceb4f432cc9099b925",
      "6d6a783fc5c84bf69732ac2139aa6ca8",
      "56dc290c15bc4f1a89dea1c3705103a2",
      "237ab2c037344631bcc00324a3eecb5f",
      "87be0fb9b2c840d18e12df9ffcac1837",
      "814a4ae828b74d75b1e01a060954121b",
      "f16d45e8062246c28bcdfd4a674a5186",
      "302aabc1520d403c9d7b4d1109a871ac",
      "75387e56e04a4ed1a16e6f05d3160a33",
      "b95fb3004584459191358de1fb088bcd",
      "9f1222f24cce468ba43052ff6f1c7ff9",
      "ddd545c888534116ad05984b4b459937",
      "db242ecf82804d438b5e9f2822748fe5",
      "b3d812a5fcb641adaf2e841864cf22f7",
      "a4568213d0bb421a9d0a5159b56955a6",
      "c463a5c60b4a4f98bc7b5cdcd0bc2e0b",
      "eac6396599b94efdb1bdc4807a17caf7",
      "22998fe70f1d4e5ca8cc7d71ae8982a0",
      "dee3bd9eb17c4f8892bdffb57e059ee8",
      "fd951108b8be402f8b8c217cfbdc5941",
      "ae06ea0f4d744241b169cd9eb197a3cd",
      "f396a4fd46204ac49e6f0218be901284",
      "43c531e07a0f4a9686b27268730692e8",
      "8d1604cab0474cdb857193fdd2177866",
      "13e65ae9754d4aae90fa7bf69eab2502",
      "4755239f0235405b9ed9131d8f2a3103",
      "a769e84a758940609c099683ab8e73c8",
      "1ff48dd63bb1492a8dbc67a109d17c87",
      "369e2f12824c4a8d8588109a10a0214e",
      "dfb75b2564c245128d26cfb29f8ae1e8",
      "0853665903e349c8a9391babd3f8af2c",
      "0ceb201f3b1d47fbb7b7786e3f249852",
      "5e62c58b0b834d5bae6add2dda68ed11",
      "882d1078f48a4bd3a2b4a3caf4630439",
      "5235c6556fed49ea9fc272ecba3a9ac7",
      "c423924b6796497c9f2022d1c0e79013",
      "fd259dd1b2dc4ec88b02bad9a08bb3ca",
      "fc6a2f06c2d4458a80e9cbad8176fc3c",
      "e2e717d44505423da42f48f7bdb4a85b",
      "24e70aec6edf42689200dc7060d3c79e",
      "7fdb8d90a3a644b38c691a5046d3221c",
      "10afa2b9d49f44acb6f957cea217fe7c",
      "aad928aad85e4497a2b7bc7a64cefe24",
      "e120db09032f468ab628c6ce02a5993a",
      "53b73f3bd7dd46d98b2082dff3b94b93",
      "2e9eac296ba44d38b8bb793f34b321c6",
      "763c0f9ea3ff4f448e391ed3c0b2c130",
      "6531f8cbbc694ce394e5d598fc304a85",
      "edfca04ca9ec4fc29875219c32589480",
      "7045c2dd66e54f3bbbd58f27aeed5452",
      "742048283cf94333b82803b00ee64d1f",
      "6f41fabd2ef9464ab952a1f5e3465c0d",
      "fcaf05f6edb84a50a907646dbc8cd811",
      "5eeefb0a875f4f4286871bbbab6d6701",
      "adcbde243ea048fabb15393802b3a043",
      "b5054fc45d2c48658debe5508854864e",
      "625d5a42cb394c18bb5229e4fe3b3339",
      "3d767e8ca82547a6844acbaa853aa932",
      "ddd0cb509d5847c7bb803cc74d098ffa",
      "ee9ed3a15b7e46918332aefe8704b3b6",
      "41ef45ac8cdd44cfafa26e2546c2d3ff",
      "8c9f9a7fceb04a16b0ef5ac2717f405e",
      "933aa7d255dd4c7a9447c18a0de1af2f",
      "cfcaacec62e648a5a39ef30e70f74d38",
      "efb777c1b989482f80d7bfe987d4b79e",
      "e76ac1e813b241b4bfa82369a6799ea1",
      "ebe39013658d41a6b469e7dc888eb416",
      "899c6863b3a94f5bae0051b1fa4fad03",
      "23bc3cdb0d1744fdb24e61e32126567d",
      "c97bd2fd2c1b47c183f9fc277fbbba2e",
      "5c8159d2da2d41c7b6aecad01c0c4104",
      "113bcb595af845e685c68745195b5e57",
      "e938ac7e129a421a835bb1593ea2f70c",
      "6bf76b1612e447408f78fbc35828261f",
      "a41f753eda254e40a32ef29f46b8aad2",
      "ab546f615d8f4586927d7a1e3fc5b73d",
      "7ed32905a1ec458fa15a907c408bfd9c",
      "d335984587394066917cf4aceb44a43b",
      "3f33d38b2da94c28a6903f5b099938e6",
      "9d0715c8a8b14635b040c7d2ee5e2c45",
      "465b063ddc54452a8c0ecefe4c59d30d",
      "dc5d77153e9e4e8fabe74ea3acbf45bb",
      "d0bd9704b17d43b78d6de30bce8b4120",
      "74e0404bd95d448183fd172bb04043d1",
      "11258a844dbf4c9fa92360838ecd6952",
      "c4173202a83444b58cc9ba1504f37dfe",
      "e93c1d8383924b43a894337d21adcdb2",
      "9e0c75d9f7c142b781a55fa61e31d72f",
      "31bc09752b714c9c9a55af0a4e331dc1",
      "d9ca34149b7642df947aabbcb71424b0",
      "3e1c1c3a8c454441a5bccc2c54556996",
      "006dd39ce50d4f31af27e5d7a189fafd",
      "baec575740da4eceaf50f6bc344e1b2c",
      "7ddf9c7b3b124841bd4737d0b2923d10",
      "a05839559540407e84813ba77d0eded4",
      "ae45507309704686aad9180daa90d746",
      "3b6cdab0a73349b9a8d773e82483d499",
      "e2add4d89e2d458eb472453b1c06fbb1",
      "046e7be3a6f94bd0aedb779fac884fbb",
      "3c2092fc0d9d4175acde20454d6b8181",
      "88826d86286c4051ac2f8289b435dd33",
      "342c0f3233844060859248593db36803",
      "b7bdb5ac3f704259a54f07a3d5a79fc3",
      "e0a958cd1d494013a3a01546b6412e18",
      "38cd1f252ba14cf08fd084ed8c1dd790",
      "19c159f632a1454bb592904bf8d70761",
      "56f8091311e94374b899195bc66ed21b",
      "0794d617b6004616882da85198b9a855",
      "1c8de7479b4545379d300088260d9571",
      "27d860cfe60c447a90ca7e0cd271c64a",
      "a28d087c2f084636a408a379a7ffb228",
      "1e42f602947045d2b8048f53399bfc4e",
      "cb437c3f859f44398bd6204982d0fea4",
      "df372ed64a4044339ebf7a5a090d68a1",
      "552a1cbab5064628bb8c57b55dc27ecb",
      "9e09976789ee46fb826cccceac8cb3c2",
      "7d79ebeb12024258a22f0bf776676850",
      "a961d5086d6a4ea1b18f3becbbe90212",
      "23317735f002432083f6f21c7a656e73",
      "66a409ab95d64adcb4c4f00e257ef5c3",
      "f13a8d3070024eeba04329489ffa08e5",
      "bb5c1c10ae4e462b967b467bc2357cf7",
      "1f5f9df5660b4dbc93fbe2d3bd0ec15d",
      "26b4a58fba1b4ab78ccceae22a26ab4a",
      "c78cb06d1cd24dd692cbbe16c5927c89",
      "3949f0b25f4a4f02b5bde7c3a9fc9592"
     ]
    },
    "id": "9e6d1af3",
    "outputId": "667c5106-58d1-4a98-8c1f-ee61b6f0a8f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully authenticated with Hugging Face.\n",
      "GPU Detected: NVIDIA A100-SXM4-40GB\n",
      "Loading model: meta-llama/Meta-Llama-3.1-8B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0b95c1641c44be8ba7903db0eaaec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814a4ae828b74d75b1e01a060954121b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac6396599b94efdb1bdc4807a17caf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff48dd63bb1492a8dbc67a109d17c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e717d44505423da42f48f7bdb4a85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7045c2dd66e54f3bbbd58f27aeed5452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ef45ac8cdd44cfafa26e2546c2d3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113bcb595af845e685c68745195b5e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bd9704b17d43b78d6de30bce8b4120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddf9c7b3b124841bd4737d0b2923d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cd1f252ba14cf08fd084ed8c1dd790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e09976789ee46fb826cccceac8cb3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Text generation pipeline initialized (Greedy Search Mode).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LOAD LLM (Meta-Llama-3.1-8B-Instruct)\n",
    "# Initializes the Llama-3.1-8B-Instruct model using 4-bit\n",
    "# quantization for memory efficiency. Authenticates using the environment\n",
    "# variable. Configured for GREEDY SEARCH (Deterministic/Temp 0) for RAG.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "# AUTHENTICATION & ENVIRONMENT SETUP\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"[ERROR] HUGGINGFACEHUB_API_TOKEN not found in environment variables.\")\n",
    "\n",
    "try:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\" Successfully authenticated with Hugging Face.\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Authentication failed: {e}\")\n",
    "    raise e\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"[ERROR] GPU not detected. CUDA is required.\")\n",
    "\n",
    "print(f\"GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# QUANTIZATION CONFIGURATION (4-bit)\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "# MODEL & TOKENIZER\n",
    "\n",
    "print(f\"Loading model: {model_id}...\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\": 0},\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        token=HF_TOKEN\n",
    "    )\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to load model: {e}\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "# PIPELINE INITIALIZATION (Deterministic)\n",
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=600,\n",
    "    return_full_text=False,\n",
    "    do_sample=False  # ENABLE GREEDY SEARCH (Temperature = 0)\n",
    ")\n",
    "\n",
    "print(\"Text generation pipeline initialized (Greedy Search Mode).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5122384",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5122384",
    "outputId": "70209b80-5ffb-408b-818d-e0d5f4928b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Vector DB at: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db\n",
      "Connecting to Graph DB at: neo4j+s://be24de9e.databases.neo4j.io\n",
      "PDF Collection: municipal_pdfs_rag\n",
      "KG Collection:  kg_structural_rag\n",
      "Distance Threshold: 1.6\n",
      "All Databases Connected. Narrative Flow Active.\n",
      "\n",
      "================================================================================\n",
      "STARTING HYBRID RAG EXECUTION CYCLE\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[QUERY] Q1: Which groups provide workshops or tools that support woodworking activities?\n",
      "--------------------------------------------------------------------------------\n",
      "Search Pattern: [woodworking|workshop|tool|activity]\n",
      "Active KG Search Terms: ['woodworking', 'activity']\n",
      "Graph Found: 9 organizations with relevant inventory.\n",
      "\n",
      "Final Answer:\n",
      "The groups that provide workshops or tools that support woodworking activities are Holzwerkstatt Gostenhof e.V. and KunstKultur Quartier Werkstatten. \n",
      "\n",
      "Holzwerkstatt Gostenhof e.V. offers a variety of woodworking tools, including Altendorf WA6 (Panel Saw), Festool TS 75 EbQ (Plunge Saw), and Lamello Classic (Flachdübelfräse), among others. Their workshop is open to members and visitors, providing a space for members to work on their own non-commercial projects in a professionally equipped woodworking shop. The membership fee and usage fee are kept low, making it an accessible option for those interested in woodworking.\n",
      "\n",
      "KunstKultur Quartier Werkstatten also provides a woodworking workshop, offering a space for DIY enthusiasts, hobbyists, and artists to work on their projects. Their workshop is open to the public, and their staff is happy to provide guidance and support to those without prior knowledge in the various disciplines. They aim to provide a space where people can engage in hands-on activities and create something with wood and other materials.\n",
      "\n",
      "Both of these groups cater to woodworking activities, providing the necessary tools and a supportive environment for members and visitors to work on their projects.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[QUERY] Q2: Which publicly accessible spaces are suitable for hosting small public meetings?\n",
      "--------------------------------------------------------------------------------\n",
      "Search Pattern: [meeting|space|room|venue|hall|lobby|lobby_area]\n",
      "Active KG Search Terms: ['meeting', 'room', 'venue', 'hall', 'lobby', 'lobby_area']\n",
      "Graph Found: 3 organizations with relevant inventory.\n",
      "\n",
      "Final Answer:\n",
      "The Heizhaus Nürnberg's Event Hall is a suitable space for hosting small public meetings. This community and event space is designed to accommodate various activities, including concerts and community gatherings. It is open to the public, making it an ideal location for small public meetings.\n",
      "\n",
      "The KLARA's KLARA Open is another suitable option. This civic participation and event space is a free, publicly accessible space for meetings, workshops, and events. Its open nature and flexibility make it an excellent choice for small public meetings.\n",
      "\n",
      "The KOLEO's Lern und Kreativwerkstatt is also a collaborative workspace suitable for meetings, creative workshops, and small civic gatherings. It is a publicly accessible space for dialogue sessions, making it a great option for small public meetings.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[QUERY] Q3: Which places support media production projects (video/audio)?\n",
      "--------------------------------------------------------------------------------\n",
      "Search Pattern: [production|studio|recording|audio|video|broadcast|editing|post_production|sound]\n",
      "Active KG Search Terms: ['production', 'studio', 'recording', 'audio', 'video', 'broadcast', 'editing', 'post_production', 'sound']\n",
      "Graph Found: 2 organizations with relevant inventory.\n",
      "\n",
      "Final Answer:\n",
      "The Diversity Media Workspace provided by Diversity Media is a suitable location for media production projects. This facility is specifically designed for media production and offers a variety of equipment and tools for creating audiovisual content. The workspace is open to the public, allowing individuals to access and utilize the equipment for their projects. Diversity Media continuously works on expanding and improving the workspace to cater to the needs of its users.\n",
      "\n",
      "The Studio für Audio und Videoproduktion, also provided by Diversity Media, is another excellent option for media production projects. This studio is equipped with recording and editing equipment for audiovisual content, making it an ideal space for producing and editing videos and audio files. The studio's primary focus is on audio and video production, making it a suitable choice for projects that require a mix of both.\n",
      "\n",
      "The MIRACL Sound Lab provided by Leonardo Zentrum is also a suitable location for media production projects, particularly those focused on audio production. This lab is equipped with various tools for recording and editing audio content, including tonaufnahmen von Sprache und Instrumenten and postproduktion: editing, mixing & mastering.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[QUERY] Q4: Which municipal facilities are suitable for a 'Repair' or 'Maintenance' project ?\n",
      "--------------------------------------------------------------------------------\n",
      "Search Pattern: [repair|municipal_facility|maintenance|project|site|construction|equipment|garage]\n",
      "Active KG Search Terms: ['repair', 'municipal_facility', 'maintenance', 'project', 'site', 'construction', 'equipment', 'garage']\n",
      "Graph Found: 5 organizations with relevant inventory.\n",
      "\n",
      "Final Answer:\n",
      "For a 'Repair' or 'Maintenance' project, the municipal facilities in Nuremberg that are suitable would be the FAU FabLab Makerspace, FAU Fahrradreparatur, and KunstKultur Quartier Werkstatten's Fahrradwerkstatt. These facilities are specifically designed for repair and maintenance activities, with FAU Fahrradreparatur being a dedicated repair and maintenance workshop, and Fahrradwerkstatt at KunstKultur Quartier Werkstatten offering repair and maintenance services for bicycles. Both of these facilities have public access, making them accessible to anyone interested in pursuing a repair or maintenance project.\n",
      "\n",
      "The FAU FabLab Makerspace, on the other hand, is a makerspace that allows users to work with various materials and tools, including those needed for repair and maintenance projects. While its primary focus is on fabrication and making, it does offer the necessary tools and resources for repair and maintenance activities.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[QUERY] Q5: Which facilities or groups provide 3D printers or 3D printing workshops?\n",
      "--------------------------------------------------------------------------------\n",
      "Search Pattern: [3d_printer|3d_printing|workshop|facility|lab|maker_space|]\n",
      "Active KG Search Terms: ['3d_printer', '3d_printing']\n",
      "Graph Found: 4 organizations with relevant inventory.\n",
      "\n",
      "Final Answer:\n",
      "The TH Nürnberg group, located at OHMlab, provides access to several 3D printers, including the Creality CR20pro, FLSUN Q5, and Prusa MINI, restricted to TH Nürnberg students. The FabLab Nürnberg offers public access to 3D printers such as the Artillery Sidewinder X1 and Prusa i3MK2. Additionally, the FabLab Nüland provides access to a Formlabs Form 1+ 3D printer, but only for its members. \n",
      "\n",
      "The Leonardo_Zentrum offers a makerspace and workshop area where you can construct and work on prototypes, featuring machines for textile work, electro and model building, 3D printing, CNC, and laser cutting. They provide various services including 3D printing with FDM and SLA methods, CNC processing, and laser cutting. The FAU FabLab has four FDM printers, including three BambuLab printers and one Ultimaker 2+, as well as one SLA printer, the UniFormation GK2.\n",
      "\n",
      "================================================================================\n",
      "EXECUTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# HYBRID RAG PIPELINE\n",
    "\n",
    "# DESCRIPTION: The core execution engine of the project. It integrates:\n",
    "# 1. LLM-Based Query Understanding, Intent Analysis & Keyword Extraction\n",
    "# 2. Semantic Vector Retrieval (ChromaDB - PDF & KG)\n",
    "# 3. Structured Graph Retrieval (Neo4j Cypher)\n",
    "# 4. Context-Aware Response Generation (Llama 3.1)\n",
    "#\n",
    "# CONFIGURATION NOTE:\n",
    "# Default settings use L2 Distance. To switch to Cosine Similarity,\n",
    "# uncomment the respective collection names AND the threshold values below.\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import re\n",
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# 1. CONFIGURATION & DATABASE INITIALIZATION\n",
    "# Define Paths\n",
    "if 'CHROMA_PATH' not in locals():\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
    "    CHROMA_PATH = os.path.join(ROOT_DIR, \"chroma_db\")\n",
    "\n",
    "# Define Credentials (from Environment)\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_AUTH = (os.getenv(\"NEO4J_USERNAME\", \"neo4j\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    "\n",
    "if not NEO4J_URI or not NEO4J_AUTH[1]:\n",
    "    raise ValueError(\"[ERROR] Neo4j credentials missing in environment variables.\")\n",
    "\n",
    "# --- METRIC & COLLECTION CONFIGURATION (L2 vs COSINE SWITCH) ---\n",
    "\n",
    "# OPTION A: L2 Distance (Default - Euclidean)\n",
    "# Lower score is better. Range usually [0, 2] for normalized vectors.\n",
    "PDF_COLLECTION_NAME = \"municipal_pdfs_rag\"\n",
    "KG_COLLECTION_NAME = \"kg_structural_rag\"\n",
    "SIMILARITY_THRESHOLD = 1.6  # High tolerance for L2\n",
    "\n",
    "# OPTION B: Cosine Similarity (Uncomment to use)\n",
    "# Distance = 1 - CosineSimilarity. Lower is better. Range [0, 1].\n",
    "# PDF_COLLECTION_NAME = \"municipal_pdfs_cosine\"\n",
    "# KG_COLLECTION_NAME = \"kg_structural_cosine\"\n",
    "# SIMILARITY_THRESHOLD = 0.4  # Stricter tolerance for Cosine Distance (approx 0.6 similarity)\n",
    "\n",
    "print(f\"Connecting to Vector DB at: {CHROMA_PATH}\")\n",
    "print(f\"Connecting to Graph DB at: {NEO4J_URI}\")\n",
    "print(f\"PDF Collection: {PDF_COLLECTION_NAME}\")\n",
    "print(f\"KG Collection:  {KG_COLLECTION_NAME}\")\n",
    "print(f\"Distance Threshold: {SIMILARITY_THRESHOLD}\")\n",
    "\n",
    "class NormalizedEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        # Normalizing queries\n",
    "        return self.model.encode(input, convert_to_numpy=True, normalize_embeddings=True).tolist()\n",
    "\n",
    "try:\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "    # [DEĞİŞTİ] Define Embedding Functions using our NORMALIZED class\n",
    "    ef_pdf = NormalizedEmbeddingFunction(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "    ef_kg = NormalizedEmbeddingFunction(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Initialize Collections\n",
    "    pdf_collection = chroma_client.get_collection(name=PDF_COLLECTION_NAME, embedding_function=ef_pdf)\n",
    "    kg_vec_collection = chroma_client.get_collection(name=KG_COLLECTION_NAME, embedding_function=ef_kg)\n",
    "\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH)\n",
    "    driver.verify_connectivity()\n",
    "    print(\"All Databases Connected. Narrative Flow Active.\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Database Connection Failed: {e}\")\n",
    "\n",
    "\n",
    "# Cleaning\n",
    "def clean_ontology_text(text):\n",
    "    if not text: return \"\"\n",
    "    text = re.sub(r'^[A-Z]\\d+_', '', text)\n",
    "    text = re.sub(r'-\\d+$', '', text)\n",
    "    text = text.replace('_', ' ')\n",
    "    text = re.sub(r'(?i)\\s(Facility|Area|Place|Object|Model|type|Group)$', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# DYNAMIC KEYWORD GENERATOR (LLM-BASED INTENT ANALYSIS WITH FEW SHOT LEARNING)\n",
    "\n",
    "def generate_dynamic_search_pattern(question: str):\n",
    "\n",
    "    #Uses the LLM to analyze user intent and extract technical keywords\n",
    "    #from the user question for targeted Graph database querying.\n",
    "\n",
    "    extraction_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a search engine backend. Extract core technical keywords in singular form.\n",
    "    Return ONLY keywords separated by pipes (|). Do not include any other text.\n",
    "    STRICT RULE: Avoid generic words like 'access', 'rules', 'organization', 'policy', 'facility'.\n",
    "\n",
    "    Q: Where is the nearest room with an MRI scanner?\n",
    "    K: mri_scanner|radiology|room\n",
    "\n",
    "    Q: I need a large venue for a corporate surgery simulation.\n",
    "    K: surgery|simulation|unit|medical|theatre|hospital\n",
    "\n",
    "    Q: Which airlock is available for EVA suits?\n",
    "    K: airlock|eva_suit|pressure_hatch\n",
    "\n",
    "    Q: I am looking for a specialized hangar for satellite maintenance.\n",
    "    K: satellite_maintenance|hangar|space|engineering|data\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Q: {question}\n",
    "    K:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "    try:\n",
    "        output = text_generation_pipeline(extraction_prompt, max_new_tokens=20, do_sample=False)[0]['generated_text']\n",
    "        raw = output.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].strip().lower()\n",
    "        clean_words = re.sub(r\"[^\\w\\|]\", \" \", raw).split()\n",
    "        forbidden = [\n",
    "            \"facility\", \"facilities\", \"group\", \"groups\", \"workshop\", \"workshops\",\n",
    "            \"based\", \"find\", \"looking\", \"where\", \"which\"\n",
    "        ]\n",
    "\n",
    "        keywords = [w for w in clean_words if len(w) > 2 and w not in forbidden]\n",
    "\n",
    "        return \"|\".join(keywords[:5])\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Keyword extraction failed: {e}\")\n",
    "        return \"facility|equipment\"\n",
    "\n",
    "# MULTI-SOURCE VECTOR RETRIEVAL\n",
    "\n",
    "def retrieve_all_embeddings(question, top_k=5):\n",
    "\n",
    "    context_data = {\"pdfs\": [], \"kg_vectors\": []}\n",
    "\n",
    "    try:\n",
    "        # --- PDF COLLECTION QUERY ---\n",
    "        res_pdf = pdf_collection.query(\n",
    "            query_texts=[question],\n",
    "            n_results=top_k,\n",
    "            include=['documents', 'metadatas', 'distances']\n",
    "        )\n",
    "\n",
    "        if res_pdf['documents']:\n",
    "            for doc, meta, dist in zip(res_pdf['documents'][0], res_pdf['metadatas'][0], res_pdf['distances'][0]):\n",
    "                if dist > SIMILARITY_THRESHOLD: continue\n",
    "                group = meta.get('e74_group', 'General Doc')\n",
    "                context_data[\"pdfs\"].append(f\"[{group}]: {doc.strip()}\")\n",
    "\n",
    "        # --- KG COLLECTION QUERY ---\n",
    "        res_kg = kg_vec_collection.query(\n",
    "            query_texts=[question],\n",
    "            n_results=top_k,\n",
    "            include=['documents', 'metadatas', 'distances']\n",
    "        )\n",
    "\n",
    "        if res_kg['documents']:\n",
    "            for doc, dist in zip(res_kg['documents'][0], res_kg['distances'][0]):\n",
    "                if dist > SIMILARITY_THRESHOLD: continue\n",
    "                context_data[\"kg_vectors\"].append(f\"{doc.strip()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Vector Retrieval Error: {e}\")\n",
    "        pass\n",
    "\n",
    "    return context_data\n",
    "\n",
    "\n",
    "# SEMANTIC CYPHER SEARCH\n",
    "\n",
    "def fetch_kg_facts(regex_pattern: str):\n",
    "    \"\"\"\n",
    "    Executes a complex Cypher query to retrieve structured facts based on\n",
    "    semantic hierarchy and keyword matching.\n",
    "    \"\"\"\n",
    "    raw_terms = [t.strip().lower() for t in regex_pattern.split('|') if len(t) > 2]\n",
    "\n",
    "    # Specificity Logic\n",
    "    specific_indicators = [\n",
    "        \"wood\", \"woodworking\", \"carpentry\", \"lathe\", \"saw\", \"drill\", \"workshop\",\n",
    "        \"garden\", \"gardening\", \"agriculture\", \"nature\", \"outdoor\", \"farm\",\n",
    "        \"textile\", \"sew\", \"tailor\",\n",
    "        \"3d_Printer\", \"3d\", \"laser\", \"cnc\", \"metal\", \"milling\", \"fabrication\",\n",
    "        \"audio\", \"video\", \"media\", \"sound\", \"lab\", \"studio\", \"record\", \"acoustic\", \"production\",\n",
    "        \"meeting\", \"conference\", \"seminar\", \"event\", \"hall\", \"social\", \"civic\",\n",
    "        \"community\", \"gathering\", \"room\", \"venue\", \"lecture\", \"exhibition\",\n",
    "        \"gallery\", \"stage\", \"performance\"\n",
    "    ]\n",
    "\n",
    "    generic_terms = [\"tool\", \"equipment\", \"machine\", \"device\", \"facility\", \"workshop\", \"space\", \"lab\"]\n",
    "\n",
    "    is_specific = any(s in term for term in raw_terms for s in specific_indicators)\n",
    "\n",
    "    if is_specific:\n",
    "        search_terms = [t for t in raw_terms if not any(g in t for g in generic_terms)]\n",
    "        if not search_terms: search_terms = raw_terms\n",
    "    else:\n",
    "        search_terms = raw_terms\n",
    "\n",
    "    print(f\"Active KG Search Terms: {search_terms}\")\n",
    "\n",
    "    access_logic = \"\"\"\n",
    "    OPTIONAL MATCH (entity)-[:P55_has_current_location]->(direct_loc)\n",
    "    OPTIONAL MATCH (owner)-[:P52i_is_current_owner_of]->(fac:E53_Place)\n",
    "    WITH entity, owner, final_type, coalesce(direct_loc.name, fac.name, \"General Facility\") AS LocName\n",
    "    OPTIONAL MATCH (restriction:E30_Right)-[:P105_right_held_by]->(owner)\n",
    "    WITH entity, owner, final_type, LocName,\n",
    "          coalesce(restriction.name, \"Public Access\") AS AccessStatus\n",
    "    \"\"\"\n",
    "\n",
    "    return_part = \"\"\"\n",
    "    RETURN owner.name AS Org,\n",
    "           LocName AS Loc,\n",
    "           entity.name AS Item,\n",
    "           coalesce(final_type.name, \"Equipment\") AS Cat,\n",
    "           coalesce(entity.P3_has_note, \"\") AS Note,\n",
    "           AccessStatus AS Access\n",
    "    \"\"\"\n",
    "\n",
    "    cypher = f\"\"\"\n",
    "    // BRANCH 1: HIERARCHY CHAIN\n",
    "    MATCH (t:E55_Type)\n",
    "    WHERE any(word IN $terms WHERE toLower(t.name) CONTAINS word)\n",
    "    MATCH (child_type:E55_Type)-[:P127_has_broader_term*0..2]->(t)\n",
    "    MATCH (entity)-[:P2_has_type]->(final_type)\n",
    "    WHERE final_type = child_type\n",
    "    AND (entity:`E22_Human-Made_Object` OR entity:`E24_Physical_Human-Made_Thing` OR entity:`E25_Human-Made_Feature`)\n",
    "    MATCH (owner:E74_Group)-[:P52i_is_current_owner_of]->(entity)\n",
    "    {access_logic}\n",
    "    {return_part}\n",
    "\n",
    "    UNION\n",
    "\n",
    "    // BRANCH 2: MODEL CHAIN\n",
    "    MATCH (t:E55_Type)\n",
    "    WHERE any(word IN $terms WHERE toLower(t.name) CONTAINS word)\n",
    "    MATCH (child_type:E55_Type)-[:P127_has_broader_term*0..2]->(t)\n",
    "    MATCH (entity)-[:P2_has_type]->(:E99_Product_Type)-[:P2_has_type]->(final_type)\n",
    "    WHERE final_type = child_type\n",
    "    MATCH (owner:E74_Group)-[:P52i_is_current_owner_of]->(entity)\n",
    "    {access_logic}\n",
    "    {return_part}\n",
    "\n",
    "    UNION\n",
    "\n",
    "    // BRANCH 3: TEXT CHAIN\n",
    "    MATCH (entity)\n",
    "    WHERE (any(word IN $terms WHERE toLower(entity.name) CONTAINS word)\n",
    "        OR any(word IN $terms WHERE toLower(entity.P3_has_note) CONTAINS word))\n",
    "    AND (entity:`E22_Human-Made_Object` OR entity:`E24_Physical_Human-Made_Thing` OR entity:`E25_Human-Made_Feature`)\n",
    "    OPTIONAL MATCH (entity)-[:P2_has_type*1..2]->(final_type:E55_Type)\n",
    "    MATCH (owner:E74_Group)-[:P52i_is_current_owner_of]->(entity)\n",
    "    {access_logic}\n",
    "    {return_part}\n",
    "    \"\"\"\n",
    "\n",
    "    full_query = f\"\"\"\n",
    "    CALL () {{\n",
    "        {cypher}\n",
    "    }}\n",
    "    WITH Org, Loc, Access, Item, Cat, Note\n",
    "    WITH Org, Loc, replace(Access, '_', ' ') AS CleanAccess, Item, replace(Cat, '_', ' ') AS CleanCat, Note\n",
    "\n",
    "    ORDER BY Item\n",
    "    RETURN Org, Loc, CleanAccess, collect(distinct {{Item: Item, Category: CleanCat, Note: Note}}) as Inventory\n",
    "    ORDER BY size(Inventory) DESC\n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            r = session.run(full_query, terms=search_terms)\n",
    "            for row in r:\n",
    "                org = clean_ontology_text(row[\"Org\"])\n",
    "                loc = clean_ontology_text(row[\"Loc\"])\n",
    "                access = row[\"CleanAccess\"]\n",
    "\n",
    "                items_with_type = []\n",
    "                for item in row[\"Inventory\"]:\n",
    "                    i_name = clean_ontology_text(item['Item'])\n",
    "                    i_cat = clean_ontology_text(item['Category'])\n",
    "\n",
    "                    if i_cat.lower() in i_name.lower():\n",
    "                        items_with_type.append(i_name)\n",
    "                    else:\n",
    "                        items_with_type.append(f\"{i_name} (type: {i_cat})\")\n",
    "\n",
    "                resources_str = \", \".join(items_with_type)\n",
    "\n",
    "                clean_org = org.lower().replace(\" \", \"\")\n",
    "                clean_loc = loc.lower().replace(\" \", \"\")\n",
    "\n",
    "                if clean_loc in clean_org or clean_org in clean_loc:\n",
    "                    segment = f\"The group '{org}' provides the following: {resources_str}. Access rule: {access}.\"\n",
    "                else:\n",
    "                    segment = f\"The group '{org}' (located at {loc}) provides the following: {resources_str}. Access rule: {access}.\"\n",
    "                results.append(segment)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Neo4j Query Failed: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# RESPONSE GENERATION (CONTEXT-AWARE NARRATIVE)\n",
    "\n",
    "def generate_full_response(question, pdf_context, kg_vec_context, kg_facts):\n",
    "\n",
    "    if not pdf_context and not kg_vec_context and not kg_facts:\n",
    "        return \"Based on the available municipal data, no relevant facilities or workshops were found matching your specific request.\"\n",
    "\n",
    "    all_narrative = \"\\n\".join(pdf_context) + \"\\n\" + \"\\n\".join(kg_vec_context)\n",
    "    kg_fact_text = \"\\n\".join(kg_facts) if kg_facts else \"NO DIRECT INVENTORY MATCH FOUND IN KG.\"\n",
    "\n",
    "    system_instruction = \"\"\"You are the Nuremberg Municipal Resource Expert. Answer using the provided Context Sources.\n",
    "\n",
    "YOUR TASK: Analyze the user's INTENT and map it to the Inventory using the following GENERAL LOGIC RULES.\n",
    "\n",

    "    1. EVIDENCE VERIFICATION (The \"Specificity\" Rule):\n",
    "       - IF the user asks for a SPECIFIC TOOL or OBJECT: You must find an EXPLICIT mention of that exact object in the source text.\n",
    "       - A general facility category (e.g., \"Workshop\", \"Makerspace\") is NOT sufficient proof that they possess a specific device.\n",
    "       - CONSEQUENCE: If the text does not explicitly list the requested item, DISCARD THE FACILITY immediately. Do not mention it.\n",
    "\n",
    "    2. FUNCTIONAL COMPATIBILITY (The \"Context\" Rule):\n",
    "       - Analyze the nature of the requested activity (e.g., Social Gathering vs. Industrial Production).\n",
    "       - Ensure the recommended facility's primary environment matches this activity.\n",
    "       - EXCLUSION: Do not recommend noise-heavy or industrial environments for social/quiet activities unless they explicitly list a dedicated event space.\n",
    "\n",
    "    3. RELEVANCE FILTERING (The \"Focus\" Rule):\n",
    "       - IF the user asks for a specific category (e.g., \"Avionics or Flight Instruments\"), ONLY mention items within that technical domain.\n",
    "       - DO NOT mention unrelated subsystems such as landing gear, engine components, or cabin interior, even if they are located in the same hangar or facility.\n",
    "       - SILENTLY OMIT all unrelated inventory parts to maintain strict focus on the user's intent.\n",
    "       - If a facility offers a diverse inventory, ONLY extract and mention the items relevant to the user's current specific question.\n",
    "       - SILENTLY OMIT unrelated departments or tools to keep the answer focused.\n",
    "       - NEVER mention about additional information about unrelated fields. If user asks something about flight, you should only strict to the question.\n",
    "\n",
    "    4. NO LISTS:\n",
    "       - Do NOT use bullet points. Write in continuous, flowing, natural paragraphs.\n",
    "\n",
    "    5. NO REDUNDANCY:\n",
    "       - Avoid repetitive phrasing regarding locations.\n",
    "       - If the Organization Name is identical or highly similar to the Location Name, do not state the location separately.\n",
    "\n",
    "    6. ENTITY CONSOLIDATION:\n",
    "       - If the source data contains multiple segments referring to the same organization, SYNTHESIZE them into a single, coherent description.\n",
    "       - Do not write separate sentences or paragraphs for the same entity.\n",
    "\n",
    "    7. ACCESS TRANSLATION:\n",
    "       - Convert raw access tags into natural language statements (e.g., \"It is open to the public\" instead of \"Public Access\").\n",
    "\n",
    "    8. NO RAW METADATA:\n",
    "       - Identify and remove internal tags (e.g., [Type: ...], [Model: ...]).\n",
    "       - Incorporate the information naturally into the sentence structure without using brackets.\n",
    "\n",
    "    9. MANDATORY OWNERSHIP STRUCTURE:\n",
    "       - You must ALWAYS present the data in a Parent-Child hierarchy.\n",
    "       - Every specific location, facility, or room must be explicitly linked to its owning Organization or Group.\n",
    "       - NEVER mention a sub-facility in isolation.\n",
    "       - Preferred phrasing: \"[Organization Name]'s [Facility Name]\" or \"The [Facility Name] provided by [Organization Name]\".\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    === SOURCE 1: VERIFIED KG INVENTORY ===\n",
    "    {kg_fact_text}\n",
    "\n",
    "    === SOURCE 2: CONTEXT (PDFs & Vectors) ===\n",
    "    {all_narrative}\n",
    "\n",
    "    === USER QUESTION ===\n",
    "    {question}\n",
    "\n",
    "    Answer in flowing paragraphs based on the RULES. DO NOT use single or double quotation marks around organization names, facilities, or tools. Treat them as proper nouns within the flow. NO BULLET POINTS. NO SUMMARIES.\"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_instruction}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    output = text_generation_pipeline(prompt, max_new_tokens=1000)[0]['generated_text']\n",
    "\n",
    "    return output.split(\"<|end_header_id|>\")[-1].replace(\"<|eot_id|>\", \"\").strip()\n",
    "\n",
    "\n",
    "# MAIN EXECUTION LOOP\n",
    "\n",
    "questions = {\n",
    "    \"Q1\": \"Which groups provide workshops or tools that support woodworking activities?\",\n",
    "    \"Q2\": \"Which publicly accessible spaces are suitable for hosting small public meetings?\",\n",
    "    \"Q3\": \"Which places support media production projects (video/audio)?\",\n",
    "    \"Q4\": \"Which municipal facilities are suitable for a 'Repair' or 'Maintenance' project ?\",\n",
    "    \"Q5\": \"Which facilities or groups provide 3D printers or 3D printing workshops?\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING HYBRID RAG EXECUTION CYCLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for q_id, q_text in questions.items():\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"[QUERY] {q_id}: {q_text}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 1. Intent Analysis & Keyword Extraction\n",
    "    regex = generate_dynamic_search_pattern(q_text)\n",
    "    print(f\"Search Pattern: [{regex}]\")\n",
    "\n",
    "    # 2. Vector Retrieval\n",
    "    embeddings_data = retrieve_all_embeddings(q_text, top_k=5)\n",
    "\n",
    "    # 3. Graph Retrieval\n",
    "    structured_facts = fetch_kg_facts(regex)\n",
    "    print(f\"Graph Found: {len(structured_facts)} organizations with relevant inventory.\")\n",
    "\n",
    "    # 4. Generation\n",
    "    answer = generate_full_response(\n",
    "        q_text,\n",
    "        embeddings_data['pdfs'],\n",
    "        embeddings_data['kg_vectors'],\n",
    "        structured_facts\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFinal Answer:\\n{answer}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
