{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16012840",
      "metadata": {
        "id": "16012840"
      },
      "source": [
        "# **HYBRID RAG SYSTEM for Sparse Municipal Environments:**\n",
        "This is the base code for our thesis, we're doing everything below, data preparing, embeddings, knowledge graph connections, running the hybrid system and testing the Hybrid RAG system performance via answering the competency questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Zo9EFvmECnbm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo9EFvmECnbm",
        "outputId": "8931b822-7404-461d-b7b3-c9389b3b4d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2026-01-05 20:20:10--  https://github.com/berkantcnr/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource/archive/refs/heads/master.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/berkantcnr/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource/zip/refs/heads/master [following]\n",
            "--2026-01-05 20:20:10--  https://codeload.github.com/berkantcnr/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/content/Hybrid-RAG-for-Sparsed-Municipal-Environments-main.zip’\n",
            "\n",
            "/content/Hybrid-RAG     [  <=>               ]  11.89M  14.0MB/s    in 0.8s    \n",
            "\n",
            "2026-01-05 20:20:11 (14.0 MB/s) - ‘/content/Hybrid-RAG-for-Sparsed-Municipal-Environments-main.zip’ saved [12470233]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/berkantcnr/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource/archive/refs/heads/master.zip -O /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-main.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "lzwELKiMDBn9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzwELKiMDBn9",
        "outputId": "fa6fd209-a180-4ab3-b7c7-fcd589fb49a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-main.zip\n",
            "4fe72ac26a12470ab85d38066ac7c2dcfb446cfc\n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/.env.example  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/.gitignore  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/README.md  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/assets/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/assets/Roboto-Regular.ttf  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/\n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/222b3978-ea66-4783-aca9-24c64f3c4272/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/222b3978-ea66-4783-aca9-24c64f3c4272/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/222b3978-ea66-4783-aca9-24c64f3c4272/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/222b3978-ea66-4783-aca9-24c64f3c4272/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/222b3978-ea66-4783-aca9-24c64f3c4272/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/3034071b-be1d-4824-992a-eedcf29a458e/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/3034071b-be1d-4824-992a-eedcf29a458e/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/3034071b-be1d-4824-992a-eedcf29a458e/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/3034071b-be1d-4824-992a-eedcf29a458e/index_metadata.pickle  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/3034071b-be1d-4824-992a-eedcf29a458e/length.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/3034071b-be1d-4824-992a-eedcf29a458e/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/403e4494-ab59-46c5-a3b7-4abe5f3990af/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/403e4494-ab59-46c5-a3b7-4abe5f3990af/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/403e4494-ab59-46c5-a3b7-4abe5f3990af/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/403e4494-ab59-46c5-a3b7-4abe5f3990af/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/403e4494-ab59-46c5-a3b7-4abe5f3990af/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/5bdba671-80b2-45e5-b20a-757763fbbb98/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/5bdba671-80b2-45e5-b20a-757763fbbb98/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/5bdba671-80b2-45e5-b20a-757763fbbb98/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/5bdba671-80b2-45e5-b20a-757763fbbb98/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/5bdba671-80b2-45e5-b20a-757763fbbb98/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/672b6221-b0fa-406f-9aa0-450d7c0c8dfd/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/672b6221-b0fa-406f-9aa0-450d7c0c8dfd/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/672b6221-b0fa-406f-9aa0-450d7c0c8dfd/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/672b6221-b0fa-406f-9aa0-450d7c0c8dfd/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/672b6221-b0fa-406f-9aa0-450d7c0c8dfd/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/702c69e9-35c1-4f0f-b8cc-4804923ca50a/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/702c69e9-35c1-4f0f-b8cc-4804923ca50a/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/702c69e9-35c1-4f0f-b8cc-4804923ca50a/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/702c69e9-35c1-4f0f-b8cc-4804923ca50a/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/702c69e9-35c1-4f0f-b8cc-4804923ca50a/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/afad20d2-a438-4c0b-a7d9-b75d338a7fea/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/afad20d2-a438-4c0b-a7d9-b75d338a7fea/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/afad20d2-a438-4c0b-a7d9-b75d338a7fea/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/afad20d2-a438-4c0b-a7d9-b75d338a7fea/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/afad20d2-a438-4c0b-a7d9-b75d338a7fea/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/cef15d3a-5a1e-46e3-9fa0-1bfc82e50115/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/cef15d3a-5a1e-46e3-9fa0-1bfc82e50115/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/cef15d3a-5a1e-46e3-9fa0-1bfc82e50115/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/cef15d3a-5a1e-46e3-9fa0-1bfc82e50115/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/cef15d3a-5a1e-46e3-9fa0-1bfc82e50115/link_lists.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/chroma.sqlite3  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/d5b95a86-1d8a-4ea3-a071-3717b95259b6/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/d5b95a86-1d8a-4ea3-a071-3717b95259b6/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/d5b95a86-1d8a-4ea3-a071-3717b95259b6/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/d5b95a86-1d8a-4ea3-a071-3717b95259b6/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/d5b95a86-1d8a-4ea3-a071-3717b95259b6/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/e58842eb-ee75-4196-bc56-65399ce904cf/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/e58842eb-ee75-4196-bc56-65399ce904cf/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/e58842eb-ee75-4196-bc56-65399ce904cf/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/e58842eb-ee75-4196-bc56-65399ce904cf/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/e58842eb-ee75-4196-bc56-65399ce904cf/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/f413d8b7-8573-43f4-ab87-0a669e6f6980/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/f413d8b7-8573-43f4-ab87-0a669e6f6980/data_level0.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/f413d8b7-8573-43f4-ab87-0a669e6f6980/header.bin  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/f413d8b7-8573-43f4-ab87-0a669e6f6980/length.bin  \n",
            " extracting: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db/f413d8b7-8573-43f4-ab87-0a669e6f6980/link_lists.bin  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/\n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/DIVERSITY_MEDIA_kontakt.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/DIVERSITY_MEDIA_media-workspace.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/DIVERSITY_MEDIA_orga.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/ESSBARE_STADT_fair-share.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/ESSBARE_STADT_leihkatalog_essbare_stadt.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/ESSBARE_STADT_main.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_elektrowerkzeuge.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_kontakt.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_main.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_3d-drucker.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_handwerkzeuge.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_lasercutter.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_multifunktionstisch.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_schneideplotter.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_textilbearbeitung_naehmaschine.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_textilbearbeitung_stickmaschine.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_textilbearbeitung_textilpresse.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_zerspanung_cnc-drehbank.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_FAU_tool_zerspanung_cnc-fraese.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NBG_main.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NBG_ueber-uns_der-verein.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NBG_ueber-uns_geraete.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NBG_ueber-uns_raeumlichkeiten.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NUELAND_index.php_das-fablab.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NUELAND_index.php_kontakt.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NUELAND_index.php_mach-mit.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NUELAND_index.php_wir-ueber-uns.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/FABLAB_NUELAND_main.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/HEIZHAUS_das-haus.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/HEIZHAUS_kontakt.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/HEIZHAUS_main.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/HOLZWERKSTATT_faq.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/HOLZWERKSTATT_main.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/HOLZWERKSTATT_maschinen.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/HOLZWERKSTATT_mitgliedschaft.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/KLARA_internet_nuernberg_engagiert_klara.html.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/KOLEO_koleo.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/KOLEO_koleo_kontakt.html.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/KUNSTKULTUR_kuenstlerhaus_haus_kontakt-1.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/KUNSTKULTUR_werkstaetten.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEIHLA_cb_itemgallery_itemcat-technik.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEIHLA_cb_itemgallery_itemcat-werkzeug-allgemein.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEIHLA_cb_itemgallery_itemcat-werkzeug-textil.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEIHLA_main.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEIHLA_nutzungsbedingungen.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEONARDO_kontakt.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEONARDO_labs.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEONARDO_labs_ar-vr-labor-studio.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEONARDO_labs_eventspace-co-working-space.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEONARDO_labs_makerspace-werkstatt.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEONARDO_labs_miracl-soundlabor-tonstudio.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/LEONARDO_ueber-uns.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/ODL_TOLLWERK_de.pdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs/OHM_LAB_einrichtungen-gesamt_administration-und-service_lehr.pdf  \n",
            "   creating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/ontology/\n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/ontology/ontology-finale.rdf  \n",
            "  inflating: Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/requirements.txt  \n"
          ]
        }
      ],
      "source": [
        "# unzip zip file\n",
        "!unzip /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-main.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Sx-wVvYO-9gW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx-wVvYO-9gW",
        "outputId": "25a8d54d-0ecf-4e0a-f8e0-a06f62a2c9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c6855b04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "c6855b04",
        "outputId": "7d704c85-b492-42cd-bad4-d1bafeeeba24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: langchain==1.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: langchain-community==0.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: langchain-text-splitters==1.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: langchain-core==1.2.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.2.6)\n",
            "Requirement already satisfied: sentence-transformers==5.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: chromadb==1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: transformers==4.57.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.57.3)\n",
            "Requirement already satisfied: accelerate==1.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (1.12.0)\n",
            "Requirement already satisfied: bitsandbytes==0.49.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.49.0)\n",
            "Requirement already satisfied: torch==2.9.0+cu126 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (2.9.0+cu126)\n",
            "Requirement already satisfied: neo4j==6.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.3)\n",
            "Requirement already satisfied: pypdf==6.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (6.5.0)\n",
            "Requirement already satisfied: fpdf2==2.8.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.8.5)\n",
            "Requirement already satisfied: requests==2.32.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (2.32.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.13.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (4.13.5)\n",
            "Requirement already satisfied: python-dotenv==1.2.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (1.2.1)\n",
            "Requirement already satisfied: ipykernel==6.17.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (6.17.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain==1.2.0->-r requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==1.2.0->-r requirements.txt (line 1)) (2.12.3)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (2.0.45)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (0.4.59)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==1.2.6->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==1.2.6->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==1.2.6->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==1.2.6->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.2.0->-r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.2.0->-r requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.2.0->-r requirements.txt (line 5)) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.2.0->-r requirements.txt (line 5)) (0.36.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (1.4.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.4.0->-r requirements.txt (line 6)) (0.38.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (1.39.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (3.11.5)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.4.0->-r requirements.txt (line 6)) (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 7)) (3.20.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 7)) (2025.11.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.12.0->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (2025.12.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0+cu126->-r requirements.txt (line 10)) (3.3.20)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.5.0 (from torch==2.9.0+cu126->-r requirements.txt (line 10))\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from neo4j==6.0.3->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from fpdf2==2.8.5->-r requirements.txt (line 13)) (0.7.1)\n",
            "Requirement already satisfied: Pillow!=9.2.*,>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from fpdf2==2.8.5->-r requirements.txt (line 13)) (11.3.0)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from fpdf2==2.8.5->-r requirements.txt (line 13)) (4.61.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.5->-r requirements.txt (line 14)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.5->-r requirements.txt (line 14)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.5->-r requirements.txt (line 14)) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.5->-r requirements.txt (line 14)) (2026.1.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4==4.13.5->-r requirements.txt (line 15)) (2.8)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->-r requirements.txt (line 17)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->-r requirements.txt (line 17)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->-r requirements.txt (line 17)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->-r requirements.txt (line 17)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->-r requirements.txt (line 17)) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->-r requirements.txt (line 17)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->-r requirements.txt (line 17)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->-r requirements.txt (line 17)) (5.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt (line 2)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt (line 2)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt (line 2)) (1.22.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb==1.4.0->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r requirements.txt (line 2)) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.4.0->-r requirements.txt (line 6)) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.4.0->-r requirements.txt (line 6)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==1.4.0->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers==5.2.0->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (4.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core==1.2.6->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.4.0->-r requirements.txt (line 6)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.4.0->-r requirements.txt (line 6)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.4.0->-r requirements.txt (line 6)) (0.30.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel==6.17.1->-r requirements.txt (line 17)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel==6.17.1->-r requirements.txt (line 17)) (5.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel==6.17.1->-r requirements.txt (line 17)) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (2.0.0)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests==2.32.5->-r requirements.txt (line 14))\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (0.10)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.2.0->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.2.0->-r requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.2.0->-r requirements.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.2.0->-r requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.4.1->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.4.1->-r requirements.txt (line 2)) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.4.0->-r requirements.txt (line 6)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.4.0->-r requirements.txt (line 6)) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.4.0->-r requirements.txt (line 6)) (5.29.5)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb==1.4.0->-r requirements.txt (line 6)) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.4.0->-r requirements.txt (line 6)) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.4.0->-r requirements.txt (line 6)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.4.0->-r requirements.txt (line 6)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb==1.4.0->-r requirements.txt (line 6)) (0.60b1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb==1.4.0->-r requirements.txt (line 6)) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb==1.4.0->-r requirements.txt (line 6)) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.2.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.2.0->-r requirements.txt (line 1)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.2.0->-r requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb==1.4.0->-r requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community==0.4.1->-r requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0+cu126->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==1.4.0->-r requirements.txt (line 6)) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==1.4.0->-r requirements.txt (line 6)) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.4.0->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.4.0->-r requirements.txt (line 6)) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.4.0->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.4.0->-r requirements.txt (line 6)) (15.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0+cu126->-r requirements.txt (line 10)) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.2.0->-r requirements.txt (line 5)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.2.0->-r requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==1.4.0->-r requirements.txt (line 6)) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (0.8.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel==6.17.1->-r requirements.txt (line 17)) (4.5.1)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.2.0->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.4.0->-r requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 17)) (0.2.14)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.4.0->-r requirements.txt (line 6)) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.4.0->-r requirements.txt (line 6)) (0.6.1)\n",
            "Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m147.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: urllib3, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: urllib3\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: urllib3 2.6.2\n",
            "    Uninstalling urllib3-2.6.2:\n",
            "      Successfully uninstalled urllib3-2.6.2\n",
            "  Attempting uninstall: triton\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: triton 3.5.1\n",
            "    Uninstalling triton-3.5.1:\n",
            "      Successfully uninstalled triton-3.5.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.13.1.3\n",
            "    Uninstalling nvidia-cufile-cu12-1.13.1.3:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.13.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12 nvidia-cusparse-cu12-12.5.4.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 triton-3.5.0 urllib3-2.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "534ad931aff848a59a8d79aeec79dc71",
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a178b7fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a178b7fe",
        "outputId": "15570510-0fb2-49cd-f7eb-d2184b9ffe03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            " ROOT_DIR: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master\n",
            " PDF Path: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs\n",
            " Font Path: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/assets/Roboto-Regular.ttf\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# SETUP\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "ROOT_DIR = os.path.abspath(os.path.join(current_dir, '.'))\n",
        "sys.path.append(ROOT_DIR)\n",
        "\n",
        "DATA_PATH = os.path.join(ROOT_DIR, \"data\", \"municipal_pdfs\")\n",
        "ASSETS_DIR = os.path.join(ROOT_DIR, \"assets\")\n",
        "FONT_PATH = os.path.join(ASSETS_DIR, \"Roboto-Regular.ttf\")\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(f\" ROOT_DIR: {ROOT_DIR}\")\n",
        "print(f\" PDF Path: {DATA_PATH}\")\n",
        "print(f\" Font Path: {FONT_PATH}\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982070ad",
      "metadata": {
        "id": "982070ad"
      },
      "source": [
        "# **DATA PREPARATION PART: **\n",
        "In municipal  domains, data is mostly unstructured and sparsed across various web portals. To address this lack of structured datasets and working effective indexing within our Vector Database, a custom data  pipeline was established.\n",
        "\n",
        "The source has 14 primary institutional websites (Parent Links). A recursive web scraping algorithm was developed to traverse these domains and their associated sub-pages, resulting in a total of 53 processed URLs.\n",
        "\n",
        "Data extraction was executed using the **BeautifulSoup4** library. A rigorous data cleaning phase followed, aimed at removing noise and unnecessary web elements—such as cookie consent banners, social media widgets, and navigation to ensure high-quality textual input.\n",
        "\n",
        "The cleaned data was subsequently converted into standardized PDF documents using the implementation provided below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c08ebc0",
      "metadata": {
        "id": "4c08ebc0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# DATA INGESTION & PDF GENERATION\n",
        "# Scrapes target municipal websites, cleans the textual content,\n",
        "# and converts structured data into standardized PDF documents for RAG ingestion.\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "from urllib.parse import urlparse, urljoin\n",
        "from bs4 import BeautifulSoup\n",
        "from fpdf import FPDF\n",
        "\n",
        "#CONFIGURATION & PATHS\n",
        "# Paths are derived dynamically from the ROOT_DIR set in the previous cell.\n",
        "# If ROOT_DIR is not defined, we calculate it relative to this notebook.\n",
        "if 'ROOT_DIR' not in locals():\n",
        "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
        "\n",
        "PDF_STORAGE_PATH = os.path.join(ROOT_DIR, \"data\", \"municipal_pdfs\")\n",
        "ASSETS_DIR = os.path.join(ROOT_DIR, \"assets\")\n",
        "FONT_PATH = os.path.join(ASSETS_DIR, \"Roboto-Regular.ttf\")\n",
        "\n",
        "# check directories exist\n",
        "os.makedirs(PDF_STORAGE_PATH, exist_ok=True)\n",
        "os.makedirs(ASSETS_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# TARGET URLs\n",
        "\n",
        "TARGETS = [\n",
        "    # DIVERSITY MEDIA\n",
        "    {\"name\": \"DIVERSITY_MEDIA\", \"url\": \"https://diversitymedia.info/media-workspace\"},\n",
        "    {\"name\": \"DIVERSITY_MEDIA\", \"url\": \"https://diversitymedia.info/orga\"},\n",
        "    {\"name\": \"DIVERSITY_MEDIA\", \"url\": \"https://diversitymedia.info/kontakt\"},\n",
        "\n",
        "    # KUNSTKULTURQUARTIER\n",
        "    {\"name\": \"KUNSTKULTUR\", \"url\": \"https://www.kunstkulturquartier.de/werkstaetten\"},\n",
        "    {\"name\": \"KUNSTKULTUR\", \"url\": \"https://www.kunstkulturquartier.de/kuenstlerhaus/haus/kontakt-1\"},\n",
        "\n",
        "    # HEIZHAUS\n",
        "    {\"name\": \"HEIZHAUS\", \"url\": \"https://www.heizhaus.org/das-haus\"},\n",
        "    {\"name\": \"HEIZHAUS\", \"url\": \"https://www.heizhaus.org/kontakt\"},\n",
        "    {\"name\": \"HEIZHAUS\", \"url\": \"https://www.heizhaus.org/\"},\n",
        "\n",
        "    # LEIHLA\n",
        "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/\"},\n",
        "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/nutzungsbedingungen/\"},\n",
        "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/cb_itemgallery/?itemcat=werkzeug-allgemein\"},\n",
        "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/cb_itemgallery/?itemcat=technik\"},\n",
        "    {\"name\": \"LEIHLA\", \"url\": \"https://leihla.bluepingu.de/cb_itemgallery/?itemcat=werkzeug-textil\"},\n",
        "\n",
        "    # ESSBARE STADT\n",
        "    {\"name\": \"ESSBARE_STADT\", \"url\": \"https://essbare-stadt-nuernberg.de/fair-share/\"},\n",
        "    {\"name\": \"ESSBARE_STADT\", \"url\": \"https://leihbar.bluepingu.de/leihkatalog_essbare_stadt/\"},\n",
        "    {\"name\": \"ESSBARE_STADT\", \"url\": \"https://essbare-stadt-nuernberg.de/#kontakt\"},\n",
        "\n",
        "    # FABLAB NÜRNBERG\n",
        "    {\"name\": \"FABLAB_NBG\", \"url\": \"https://fablab-nuernberg.de/\"},\n",
        "    {\"name\": \"FABLAB_NBG\", \"url\": \"https://fablab-nuernberg.de/ueber-uns/der-verein\"},\n",
        "    {\"name\": \"FABLAB_NBG\", \"url\": \"https://fablab-nuernberg.de/ueber-uns/raeumlichkeiten\"},\n",
        "    {\"name\": \"FABLAB_NBG\", \"url\": \"https://fablab-nuernberg.de/ueber-uns/geraete\"},\n",
        "\n",
        "    # HOLZWERKSTATT GOSTENHOF\n",
        "    {\"name\": \"HOLZWERKSTATT\", \"url\": \"http://holzwerkstatt-gostenhof.de/\"},\n",
        "    {\"name\": \"HOLZWERKSTATT\", \"url\": \"http://holzwerkstatt-gostenhof.de/maschinen/\"},\n",
        "    {\"name\": \"HOLZWERKSTATT\", \"url\": \"http://holzwerkstatt-gostenhof.de/mitgliedschaft/\"},\n",
        "    {\"name\": \"HOLZWERKSTATT\", \"url\": \"http://holzwerkstatt-gostenhof.de/faq/\"},\n",
        "\n",
        "    # LEONARDO\n",
        "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/\"},\n",
        "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/makerspace-werkstatt/\"},\n",
        "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/ar-vr-labor-studio/\"},\n",
        "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/miracl-soundlabor-tonstudio/\"},\n",
        "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/labs/eventspace-co-working-space/\"},\n",
        "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/kontakt/\"},\n",
        "    {\"name\": \"LEONARDO\", \"url\": \"https://leonardo-zentrum.de/ueber-uns/\"},\n",
        "\n",
        "    # FABLAB NÜLAND\n",
        "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/\"},\n",
        "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/index.php/wir-ueber-uns\"},\n",
        "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/index.php/das-fablab\"},\n",
        "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/index.php/mach-mit\"},\n",
        "    {\"name\": \"FABLAB_NUELAND\", \"url\": \"https://fablab.nueland.de/index.php/kontakt\"},\n",
        "\n",
        "    # KOLEO\n",
        "    {\"name\": \"KOLEO\", \"url\": \"https://www.iska-nuernberg.de/koleo/\"},\n",
        "    {\"name\": \"KOLEO\", \"url\": \"https://www.iska-nuernberg.de/koleo/kontakt.html\"},\n",
        "\n",
        "    # KLARA\n",
        "    {\"name\": \"KLARA\", \"url\": \"https://www.nuernberg.de/internet/nuernberg_engagiert/klara.html\"},\n",
        "\n",
        "    # OHMLAB\n",
        "    {\"name\": \"OHM_LAB\", \"url\": \"https://www.th-nuernberg.de/einrichtungen-gesamt/administration-und-service/lehr-und-kompetenzentwicklung/lehr-und-lernraeume/ohmlab-maker-und-coworking-space/\"},\n",
        "\n",
        "    # FABLAB FAU\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/lasercutter/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/3d-drucker/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/schneideplotter/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/zerspanung/cnc-fraese/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/zerspanung/cnc-drehbank/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/elektrowerkzeuge/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/handwerkzeuge/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/textilbearbeitung/naehmaschine/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/textilbearbeitung/stickmaschine/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/textilbearbeitung/textilpresse/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/tool/multifunktionstisch/\"},\n",
        "    {\"name\": \"FABLAB_FAU\", \"url\": \"https://fablab.fau.de/kontakt/\"},\n",
        "\n",
        "    # --- ODL ---\n",
        "    {\"name\": \"ODL_TOLLWERK\", \"url\": \"https://odl-nbg.de/de/\"}\n",
        "]\n",
        "\n",
        "# Cleaning functions\n",
        "\n",
        "def get_junk_list():\n",
        "\n",
        "    return [\n",
        "        # Navigation\n",
        "        \"home\", \"startseite\", \"menu\", \"menü\", \"hauptmenü\", \"untermenü\",\n",
        "        \"navigation\", \"breadcrumb\", \"you are here\", \"sie sind hier\",\n",
        "        \"suche\", \"search\", \"suchen\", \"lupe\", \"leiste öffnen\",\n",
        "        \"zum inhalt springen\", \"skip to content\", \"zur hauptnavigation\",\n",
        "        \"navigation ausklappen\", \"top of page\", \"bottom of page\",\n",
        "        # Footer & Legal\n",
        "        \"impressum\", \"datenschutz\", \"privacy\", \"disclaimer\", \"haftungsausschluss\",\n",
        "        \"agb\", \"nutzungsbedingungen\", \"copyright\", \"alle rechte vorbehalten\",\n",
        "        \"powered by\", \"theme by\", \"wordpress\", \"secured by miniorange\",\n",
        "        # Cookie Consent\n",
        "        \"gdpr\", \"cookie\", \"cookies\", \"unbedingt notwendige cookies\",\n",
        "        \"einstellungen speichern\", \"alle aktivieren\", \"deaktiviert\", \"aktiviert\",\n",
        "        \"cookie-informationen\", \"cookie-einstellungen\",\n",
        "        # Actions & Auth\n",
        "        \"login\", \"anmelden\", \"register\", \"registrieren\", \"logout\", \"abmelden\",\n",
        "        \"warenkorb\", \"cart\", \"kasse\", \"checkout\", \"mein konto\",\n",
        "        \"passwort vergessen\", \"remember me\", \"mehr erfahren\", \"weiterlesen\",\n",
        "        # Social Media\n",
        "        \"instagram\", \"facebook\", \"youtube\", \"twitter\", \"linkedin\", \"rss\", \"feed\",\n",
        "        \"envelope\", \"google+\", \"xing\",\n",
        "        # Accessibility\n",
        "        \"barrierefreiheit\", \"text vergrößern\", \"graustufen\", \"kontrast\",\n",
        "        \"hoher kontrast\", \"heller modus\", \"links unterstreichen\", \"lesbare schriftart\",\n",
        "        \"nach oben\", \"top\", \"reset\", \"text verkleinern\", \"schriftgröße\"\n",
        "    ]\n",
        "\n",
        "def clean_text(text, url):\n",
        "\n",
        "    lines = text.splitlines()\n",
        "    cleaned_lines = []\n",
        "    junk_exact = get_junk_list()\n",
        "\n",
        "    # Specific sidebar content for FAU FabLab\n",
        "    fau_sidebar = [\n",
        "        \"was ist ein fablab\", \"wie werde ich fablab-betreuer:in?\", \"termine\",\n",
        "        \"ausstattung\", \"maschinen im überblick\", \"preise\", \"bilder\", \"projekte\",\n",
        "        \"projekte unserer besucher\", \"forschungs- und abschlussarbeiten\",\n",
        "        \"project group diybio - build your own biotech lab\", \"english\"\n",
        "    ]\n",
        "\n",
        "    for line in lines:\n",
        "        original = line.strip()\n",
        "        lower_line = original.lower()\n",
        "\n",
        "        if not original: continue\n",
        "        if lower_line in junk_exact: continue\n",
        "\n",
        "        # Fix specific glitch in Bluepingu/Leihla site\n",
        "        if \"leihla\" in url:\n",
        "            if re.search(r'\\d{10,}', original):\n",
        "                original = re.sub(r'\\d{10,}', ' ', original).strip()\n",
        "                lower_line = original.lower()\n",
        "                if not original or original in [\"Fürth\", \"Marktplatz\"]:\n",
        "                    continue\n",
        "\n",
        "        if re.match(r'^\\d+$', original): continue\n",
        "        if re.search(r'\\(PDF, \\d+ KB\\)', original): continue\n",
        "        if original.startswith(\"<\") and original.endswith(\">\"): continue\n",
        "        if \"cookie\" in lower_line and (\"verwend\" in lower_line or \"einstellung\" in lower_line): continue\n",
        "        if \"gdpr\" in lower_line: continue\n",
        "        if \"instagram.com\" in lower_line or \"facebook.com\" in lower_line: continue\n",
        "        if \"source:\" in lower_line: continue\n",
        "        if \"internetverbindung abgebrochen\" in lower_line: continue\n",
        "        if \"spambots geschützt\" in lower_line: continue\n",
        "        if \"fablab-nuernberg\" in url:\n",
        "            if any(x in lower_line for x in [\"openlab\", \"kidslab\", \"repaircafé\", \"textilelab\"]) and len(original) < 25:\n",
        "                continue\n",
        "        if \"fablab.fau\" in url:\n",
        "            if lower_line in fau_sidebar: continue\n",
        "            if len(original) < 40 and any(x in lower_line for x in [\"3d-drucker\", \"lasercutter\", \"schneideplotter\", \"elektronik\", \"textilbearbeitung\", \"zerspanung\"]):\n",
        "                # Context check: preserve if the page itself is about that topic\n",
        "                is_current_topic = False\n",
        "                if \"lasercutter\" in lower_line and \"lasercutter\" in url: is_current_topic = True\n",
        "                if \"3d-drucker\" in lower_line and \"3d-drucker\" in url: is_current_topic = True\n",
        "                if \"schneideplotter\" in lower_line and \"schneideplotter\" in url: is_current_topic = True\n",
        "                if \"elektronik\" in lower_line and \"elektro\" in url: is_current_topic = True\n",
        "                if \"textil\" in lower_line and \"textil\" in url: is_current_topic = True\n",
        "                if \"zerspanung\" in lower_line and \"zerspanung\" in url: is_current_topic = True\n",
        "\n",
        "                if not is_current_topic:\n",
        "                    continue\n",
        "\n",
        "        cleaned_lines.append(original)\n",
        "\n",
        "    return '\\n'.join(cleaned_lines)\n",
        "\n",
        "def get_soup(url):\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "        response = requests.get(url, headers=headers, timeout=15)\n",
        "        response.raise_for_status()\n",
        "        return BeautifulSoup(response.content, 'html.parser')\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Network issue with {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_pdf(text, url, filename):\n",
        "\n",
        "    # check font exists, download if necessary\n",
        "    if not os.path.exists(FONT_PATH):\n",
        "        print(f\"Roboto font not found at {FONT_PATH}. Downloading...\")\n",
        "        font_url = \"https://github.com/google/fonts/raw/main/ofl/roboto/Roboto-Regular.ttf\"\n",
        "        r = requests.get(font_url, allow_redirects=True)\n",
        "        with open(FONT_PATH, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "        print(\"Font downloaded.\")\n",
        "\n",
        "    try:\n",
        "        pdf = FPDF()\n",
        "        pdf.add_page()\n",
        "        pdf.add_font('Roboto', '', FONT_PATH)\n",
        "        pdf.set_font('Roboto', '', 8)\n",
        "        pdf.set_text_color(100, 100, 100)\n",
        "        pdf.cell(0, 10, f\"Source: {url}\", new_x=\"LMARGIN\", new_y=\"NEXT\")\n",
        "        pdf.ln(5)\n",
        "        pdf.set_font('Roboto', '', 11)\n",
        "        pdf.set_text_color(0, 0, 0)\n",
        "\n",
        "        # Safe encode/decode to handle non-latin characters roughly(necessary for german websites)\n",
        "        safe_text = text.encode('utf-8', 'replace').decode('utf-8')\n",
        "        pdf.multi_cell(0, 6, safe_text)\n",
        "        pdf.output(filename)\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to generate PDF for {url}: {e}\")\n",
        "\n",
        "# EXECUTION\n",
        "def execute_data_ingestion():\n",
        "    print(f\"Saving PDFs to: {PDF_STORAGE_PATH}\")\n",
        "\n",
        "    # Clean up existing PDF directory to ensure fresh data\n",
        "    if os.path.exists(PDF_STORAGE_PATH):\n",
        "        shutil.rmtree(PDF_STORAGE_PATH)\n",
        "    os.makedirs(PDF_STORAGE_PATH)\n",
        "\n",
        "    processed_urls = set()\n",
        "    count = 0\n",
        "\n",
        "    # Specific part for Essbare Stadt(devices are inside another website link as catalog)\n",
        "    expanded_targets = list(TARGETS)\n",
        "    for item in TARGETS:\n",
        "        if \"leihkatalog_essbare_stadt\" in item['url']:\n",
        "            print(\"Expanding Essbare Stadt Catalog...\")\n",
        "            soup = get_soup(item['url'])\n",
        "            if soup:\n",
        "                for a in soup.find_all('a', href=True):\n",
        "                    href = a['href']\n",
        "                    if \"itemcat\" in href:\n",
        "                        full_url = urljoin(item['url'], href)\n",
        "                        expanded_targets.append({\"name\": \"ESSBARE_STADT\", \"url\": full_url})\n",
        "\n",
        "    # Process all targets\n",
        "    for item in expanded_targets:\n",
        "        url = item['url']\n",
        "        institute_name = item['name']\n",
        "        base_url = url.split('#')[0]\n",
        "\n",
        "        if base_url in processed_urls: continue\n",
        "\n",
        "        print(f\"{institute_name}: {url}\")\n",
        "        soup = get_soup(url)\n",
        "        if not soup: continue\n",
        "\n",
        "        raw_text = soup.get_text()\n",
        "        final_text = clean_text(raw_text, url)\n",
        "\n",
        "        if len(final_text) < 20:\n",
        "            print(\"Content too short (possibly empty or protected).\")\n",
        "            continue\n",
        "\n",
        "        # filename\n",
        "        path_slug = urlparse(url).path.strip(\"/\").replace(\"/\", \"_\") or \"main\"\n",
        "        query_slug = urlparse(url).query.replace(\"=\", \"-\").replace(\"&\", \"_\")\n",
        "        safe_slug = f\"{path_slug}_{query_slug}\".strip(\"_\")\n",
        "        if not safe_slug: safe_slug = \"main\"\n",
        "\n",
        "        full_name = f\"{institute_name}_{safe_slug}\"[:60]\n",
        "        filename = os.path.join(PDF_STORAGE_PATH, f\"{full_name}.pdf\")\n",
        "\n",
        "        create_pdf(final_text, url, filename)\n",
        "        processed_urls.add(base_url)\n",
        "        count += 1\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    print(f\"\\n PDF creation finished. Created {count} PDFs in {PDF_STORAGE_PATH}\")\n",
        "\n",
        "# Note: Since we already have the PDFs in './municipal_pdfs',\n",
        "# you can remove comment below out if you want to re-scrape.\n",
        "# execute_data_ingestion()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f00e6ac1",
      "metadata": {
        "id": "f00e6ac1"
      },
      "source": [
        "Web scraping and data cleaning completed, pdfs created and ready in the path: /data/municipal_pdfs\n",
        "\n",
        "\n",
        "After creation of the PDFs, next step is create embeddings for Vector DB and KG and metadata tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "22eab94d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e83ae8ec52f48b1b66f3a1dddd58b0f",
            "c6c6c184df9f4edb8b2cefe7cae64822",
            "ec1c6fde995e4f8583e1a37b77c53644",
            "2ce4e4c92c7447239fbac9bac40bb820",
            "820e6576daf74ddb88adf339d604d231",
            "de01cdc103f04836905c459e2e176c00",
            "39c7b187296140f9a65590209ea4ff38",
            "7d1c76f3f93b4e1bb0c98b9c166db507",
            "b71af62b586d452f8923a6ddee2c7c32",
            "a23618e4949d4f75b8503b6820a29eb8",
            "c309519e4482435ebe64ea5f1c2df297",
            "f73ac49b16bd44848180280c148024e3",
            "f6191faac03446dea18bcfe9e71d9e43",
            "24842174895c43dca530757ecf7f8c5a",
            "c4d874e9fe694f6c99da19842a781dd3",
            "544fddd98e10438194e7108cab471aa4",
            "5f6ae29c59e64f52898e601a2b817ed5",
            "c08cd51a0dd24e1e9337bd716aaa181a",
            "616cb4e3fd00442faaf44e272dfeb15e",
            "01580f70330d427984e7e6374f83c838",
            "a617e0c66958428fa459a86db6319eda",
            "16f1e45355d34beea15c6490d7da5819",
            "50eb35d8e8dd4609bd8786bc5f2baf00",
            "98cf164149414d19941215387e3e0d43",
            "c0104f0dd0be4ece873644e598198a6a",
            "d58ade987f724d03bc93ac5469b1e85d",
            "e8075770d5f84ff5b6075aa961bbc8b1",
            "f6f4b5fb1b94470ebd942b04d716d16e",
            "682fec8556794178895eb600f9659273",
            "7411c162aeab484ba605f4204e96c85a",
            "c02f48b681244381819b1b2c7bcb0678",
            "06a84d64e58a4c788d98a2f8a3e06712",
            "93bdafa5bcf74d9caa38bab7c67f6364",
            "49a0e0c648304ed78d56fd75cc55f5c1",
            "2b6ebcb0da7048639f3c2d20916a1d52",
            "3f7e7f9b100548139dd8625890bdc2a6",
            "2bffac51548c4c09af9ea2e33ed82823",
            "a80ca3a524e84f878666f895bca8b456",
            "d6745790e28a49d1a0ead1fcabcc86cc",
            "6369c547c8314efb91debe8e4f507287",
            "be16134c6658441f98863749872d0607",
            "622ec16b2ea2490ebf4fd030bffb7ad7",
            "0d0b61400cc748df9a7ec383ca2c6214",
            "5508cd60e80d4871869c0cc7797c82d9",
            "f814aaa9bd36472594e1c56580462f8a",
            "efa8d4cbd01f4eb4bb59928dc147ee73",
            "982d7931155e49d096aa95ca302d4180",
            "ccea2f19014349c398417d56710069fb",
            "a3b88ab2c11f4aca8494dc85717368a3",
            "4fc83c3794ea4157ba056bd677f352d9",
            "586c48e8006b48b8adcc62d13e240c5d",
            "b0300b4f14e546ebb25d613621203d3e",
            "e10c56c78b4e44148cc3b94d289411c7",
            "1747d977d2c84fe8b73b89938233d39c",
            "507ab84ff20d4c128c51c1a692c50330",
            "284ae7b12fd0423f839651bf77bfd559",
            "32c8eeaa64c64c629e36916a195edbb6",
            "35bcd27160134e5291a5e78075a42ec0",
            "4982c910f277494dabbce5ac5756e5e1",
            "d91af3e35f3846059656871e38c598a3",
            "9f9c0313e2ce45a1b2bce5aa48d49a8f",
            "965565597ac64bf6909aff00446dc60d",
            "5309cf0899004f3fb4563de86bcedea0",
            "e789dd8d9aca403c9a9502acfde47718",
            "5aa8ce3f8d594bc2b26c1a1612c1fdbe",
            "d3bf1bca134244fab5963a09c3119296",
            "19a9810af29e4a9eb0417e266f77eee4",
            "076d10a1ef82430baf3b2e4a34aee841",
            "3244d87a069440409c387640d3910cb2",
            "fe590f90bbef47cda517f9f3cfad179d",
            "d4557da2d1254bdba858db6b4947bcb5",
            "6607ca23347d4c50bec1a623c0b2ae6a",
            "54b16ff5d952400cbb08ca4e40899ba5",
            "0686dec4d151470ea2cd7d98addab41d",
            "4feee03e1b0f447eb8a1f903a37a3586",
            "46fabeb4bf7c4a9aa1468a4fb0d7fd6f",
            "36004ad16f374e6592b2098caa43d290",
            "2a8b315b32ed4d79ba7916421e7a7976",
            "8ba67d7ae294445f9cf319de9b75e2e2",
            "4edfe6aa811c46d995f784343cbb6862",
            "0461cd4dcc3640ae9bc4ba12b5b27796",
            "f1616d76eb6a4e76a0e7814d137f4d90",
            "98051c96104044058329260e85bf59cb",
            "d31ef45ba4094b039164fca50a3b52df",
            "f62b2a4b9de5489295e22b5a93d5d165",
            "852e513e0cd04efa9bc3248f7ae9eab5",
            "671e62035a3e4ba69f587eadd439c09c",
            "b94b644f04f04f9dbaaedf2355815f13",
            "f588a4c431004f39a73cf511da8588ed",
            "2923d6165b84419c8fddb22067e793d2",
            "aa6d15fe3445423389ba2e34edceaf11",
            "a21d9b42dd3b4f9cb191198dd9abaa01",
            "309f8e3ee72e4ed888623a073d598eee",
            "8116f352369e402da82479994049aef1",
            "7d2e70b0473c4dac9796ab05973dbcf5",
            "d84ba143fd54444ca1bcad2a769126d6",
            "35b3fe3dbc874669847d1b940bf28ae0",
            "6746032b39014d0e9cf56f1d08076e77",
            "5bab1527ff9f4120b9e297c0e443d869",
            "7a32ba729f9c499b8688d650656ca6c8",
            "b85c9f866de34a949e2adaf13e924ac2",
            "ad6e951e958f4306834aa4d1a2863d80",
            "ce1646b2a9764c0891ff858c8b6994c9",
            "74bfab4908f64a3ebcd91c7d36d16c1f",
            "3d907c67788248ce9215001b57c71900",
            "49cd5a10a458413d9492d04b9b283d2a",
            "cde6e38802614127aa0dda56d8a5af8e",
            "3db6b270eef1406e81fccf0ec287d5eb",
            "71a837721ff242ada456a3f165ec1529",
            "afafcef20c8a497c975581ac46525543",
            "68a4ab410c9e44bf97f30473243c0d63",
            "6bb64cea802a4c0492482f1d4080d03e",
            "5959ed1aba044c808a958763b058520d",
            "cbef8026993a4873872d022799623d67",
            "075dcf6c83e146419852e8c62896c7b9",
            "99d851b729c74088ac96a5bb910cde71",
            "7b4aae7f571d4d09ba89c7cc7fa700e3",
            "b3ac91f2c495498b8917af834241f39d",
            "fe56f2e057d341409b8b1d22708ecd78",
            "83816aaf446946ce93fb1a2b69dd391f",
            "b16f6bcc08fb4066b813b6957023e16d"
          ]
        },
        "id": "22eab94d",
        "outputId": "9f87c5ad-5fa2-4ba9-cfad-e4f2d9b82ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF Source: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/data/municipal_pdfs\n",
            "Vector DB Target: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db\n",
            " Deleted existing collection: municipal_pdfs_rag\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e83ae8ec52f48b1b66f3a1dddd58b0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f73ac49b16bd44848180280c148024e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50eb35d8e8dd4609bd8786bc5f2baf00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49a0e0c648304ed78d56fd75cc55f5c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f814aaa9bd36472594e1c56580462f8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "284ae7b12fd0423f839651bf77bfd559",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19a9810af29e4a9eb0417e266f77eee4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a8b315b32ed4d79ba7916421e7a7976",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f588a4c431004f39a73cf511da8588ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a32ba729f9c499b8688d650656ca6c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68a4ab410c9e44bf97f30473243c0d63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 54 PDFs. Processing...\n",
            "Processed: DIVERSITY_MEDIA_kontakt.pdf\n",
            "Processed: DIVERSITY_MEDIA_media-workspace.pdf\n",
            "Processed: DIVERSITY_MEDIA_orga.pdf\n",
            "Processed: ESSBARE_STADT_fair-share.pdf\n",
            "Processed: ESSBARE_STADT_leihkatalog_essbare_stadt.pdf\n",
            "Processed: ESSBARE_STADT_main.pdf\n",
            "Processed: FABLAB_FAU_elektrowerkzeuge.pdf\n",
            "Processed: FABLAB_FAU_kontakt.pdf\n",
            "Processed: FABLAB_FAU_main.pdf\n",
            "Processed: FABLAB_FAU_tool_3d-drucker.pdf\n",
            "Processed: FABLAB_FAU_tool_handwerkzeuge.pdf\n",
            "Processed: FABLAB_FAU_tool_lasercutter.pdf\n",
            "Processed: FABLAB_FAU_tool_multifunktionstisch.pdf\n",
            "Processed: FABLAB_FAU_tool_schneideplotter.pdf\n",
            "Processed: FABLAB_FAU_tool_textilbearbeitung_naehmaschine.pdf\n",
            "Processed: FABLAB_FAU_tool_textilbearbeitung_stickmaschine.pdf\n",
            "Processed: FABLAB_FAU_tool_textilbearbeitung_textilpresse.pdf\n",
            "Processed: FABLAB_FAU_tool_zerspanung_cnc-drehbank.pdf\n",
            "Processed: FABLAB_FAU_tool_zerspanung_cnc-fraese.pdf\n",
            "Processed: FABLAB_NBG_main.pdf\n",
            "Processed: FABLAB_NBG_ueber-uns_der-verein.pdf\n",
            "Processed: FABLAB_NBG_ueber-uns_geraete.pdf\n",
            "Processed: FABLAB_NBG_ueber-uns_raeumlichkeiten.pdf\n",
            "Processed: FABLAB_NUELAND_index.php_das-fablab.pdf\n",
            "Processed: FABLAB_NUELAND_index.php_kontakt.pdf\n",
            "Processed: FABLAB_NUELAND_index.php_mach-mit.pdf\n",
            "Processed: FABLAB_NUELAND_index.php_wir-ueber-uns.pdf\n",
            "Processed: FABLAB_NUELAND_main.pdf\n",
            "Processed: HEIZHAUS_das-haus.pdf\n",
            "Processed: HEIZHAUS_kontakt.pdf\n",
            "Processed: HEIZHAUS_main.pdf\n",
            "Processed: HOLZWERKSTATT_faq.pdf\n",
            "Processed: HOLZWERKSTATT_main.pdf\n",
            "Processed: HOLZWERKSTATT_maschinen.pdf\n",
            "Processed: HOLZWERKSTATT_mitgliedschaft.pdf\n",
            "Processed: KLARA_internet_nuernberg_engagiert_klara.html.pdf\n",
            "Processed: KOLEO_koleo.pdf\n",
            "Processed: KOLEO_koleo_kontakt.html.pdf\n",
            "Processed: KUNSTKULTUR_kuenstlerhaus_haus_kontakt-1.pdf\n",
            "Processed: KUNSTKULTUR_werkstaetten.pdf\n",
            "Processed: LEIHLA_cb_itemgallery_itemcat-technik.pdf\n",
            "Processed: LEIHLA_cb_itemgallery_itemcat-werkzeug-allgemein.pdf\n",
            "Processed: LEIHLA_cb_itemgallery_itemcat-werkzeug-textil.pdf\n",
            "Processed: LEIHLA_main.pdf\n",
            "Processed: LEIHLA_nutzungsbedingungen.pdf\n",
            "Processed: LEONARDO_kontakt.pdf\n",
            "Processed: LEONARDO_labs.pdf\n",
            "Processed: LEONARDO_labs_ar-vr-labor-studio.pdf\n",
            "Processed: LEONARDO_labs_eventspace-co-working-space.pdf\n",
            "Processed: LEONARDO_labs_makerspace-werkstatt.pdf\n",
            "Processed: LEONARDO_labs_miracl-soundlabor-tonstudio.pdf\n",
            "Processed: LEONARDO_ueber-uns.pdf\n",
            "Processed: ODL_TOLLWERK_de.pdf\n",
            "Processed: OHM_LAB_einrichtungen-gesamt_administration-und-service_lehr.pdf\n",
            "Upserting 742 chunks into 'municipal_pdfs_rag'...\n",
            "Vector Database populated. Total chunks: 742\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# VECTOR DATABASE CREATION & PDF EMBEDDING\n",
        "\n",
        "# Reads processed PDFs, metadata tagging (E74),\n",
        "# chunks the text, and creates embeddings in ChromaDB.\n",
        "#\n",
        "# CONFIGURATION NOTE:\n",
        "# This script is configured by default to use L2 (Euclidean) distance.\n",
        "# To use Cosine Similarity, uncomment the specific metadata configuration\n",
        "# in the 'Initialize Collection' section below.\n",
        "\n",
        "import os\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from pypdf import PdfReader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# PATH CONFIGURATION\n",
        "\n",
        "if 'DATA_PATH' not in locals() or 'CHROMA_PATH' not in locals():\n",
        "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
        "    DATA_PATH = os.path.join(ROOT_DIR, \"data\", \"municipal_pdfs\")\n",
        "    CHROMA_PATH = os.path.join(ROOT_DIR, \"chroma_db\")\n",
        "\n",
        "print(f\"PDF Source: {DATA_PATH}\")\n",
        "print(f\"Vector DB Target: {CHROMA_PATH}\")\n",
        "\n",
        "# ENTITY MAPPING (PDF FILENAME -> KNOWLEDGE GRAPH GROUP)\n",
        "\n",
        "PDF_TO_E74 = {\n",
        "    \"DIVERSITY_MEDIA\": \"Diversity_Media\",\n",
        "    \"ESSBARE_STADT\": \"essbare_Stadt_Nürnberg_e.V.\",\n",
        "    \"FABLAB_FAU\": \"FAU_FabLab\",\n",
        "    \"FABLAB_NBG\": \"FabLab_Nürnberg\",\n",
        "    \"FABLAB_NUELAND\": \"FabLab_Nüland\",\n",
        "    \"HEIZHAUS\": \"Heizhaus_Nürnberg\",\n",
        "    \"HOLZWERKSTATT\": \"Holzwerkstatt_Gostenhof_e.V.\",\n",
        "    \"KLARA\": \"KLARA\",\n",
        "    \"KOLEO\": \"KOLEO\",\n",
        "    \"KUNSTKULTUR\": \"KunstKultur_Quartier_Werkstatten\",\n",
        "    \"LEIHLA\": \"Leihla_Nürnberg\",\n",
        "    \"LEONARDO\": \"Leonardo_Zentrum\",\n",
        "    \"ODL_TOLLWERK\": \"tollwerk_GmbH\",\n",
        "    \"OHM_LAB\": \"TH_Nürnberg\",\n",
        "}\n",
        "\n",
        "def infer_e74_group(filename: str) -> str:\n",
        "    for prefix, e74 in PDF_TO_E74.items():\n",
        "        if filename.startswith(prefix + \"_\"):\n",
        "            return e74\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "\n",
        "# INITIALIZE CHROMA CLIENT & COLLECTION\n",
        "client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
        "\n",
        "#  CONFIGURATION SWITCH\n",
        "# Option A: Standard L2 Distance (Default)\n",
        "COLLECTION_NAME = \"municipal_pdfs_rag\"\n",
        "\n",
        "# Option B: Cosine Similarity (Uncomment to use)\n",
        "# COLLECTION_NAME = \"municipal_pdfs_cosine\"\n",
        "\n",
        "try:\n",
        "    client.delete_collection(name=COLLECTION_NAME)\n",
        "    print(f\" Deleted existing collection: {COLLECTION_NAME}\")\n",
        "except:\n",
        "    print(f\" Collection {COLLECTION_NAME} did not exist. Creating new.\")\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Embedding Model\n",
        "class NormalizedEmbeddingFunction(chromadb.EmbeddingFunction):\n",
        "    def __init__(self, model_name):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def __call__(self, input):\n",
        "        # normalize_embeddings\n",
        "        return self.model.encode(input, convert_to_numpy=True, normalize_embeddings=True).tolist()\n",
        "\n",
        "\n",
        "ef = NormalizedEmbeddingFunction(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "# Create Collection\n",
        "\n",
        "# OPTION A: Standard Creation (L2 Distance) - ACTIVE\n",
        "collection = client.create_collection(\n",
        "    name=COLLECTION_NAME,\n",
        "    embedding_function=ef\n",
        ")\n",
        "\n",
        "# OPTION B: Cosine Similarity Configuration - INACTIVE\n",
        "# Uncomment the block below to enable Cosine Similarity but normalized l2 = cosine similarity\n",
        "# collection = client.create_collection(\n",
        "#     name=COLLECTION_NAME,\n",
        "#     embedding_function=ef,\n",
        "#     metadata={\"hnsw:space\": \"cosine\"} # Critical for Cosine Similarity\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "# CHUNKING Config\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=100,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        ")\n",
        "\n",
        "# EXECUTION: PROCESS & EMBED\n",
        "\n",
        "def build_vector_database():\n",
        "    if not os.path.exists(DATA_PATH):\n",
        "        print(f\"[ERROR] PDF directory not found: {DATA_PATH}\")\n",
        "        return\n",
        "\n",
        "    pdf_files = [f for f in os.listdir(DATA_PATH) if f.endswith(\".pdf\")]\n",
        "    print(f\"Found {len(pdf_files)} PDFs. Processing...\")\n",
        "\n",
        "    all_chunks, all_metas, all_ids = [], [], []\n",
        "\n",
        "    for filename in sorted(pdf_files):\n",
        "        file_path = os.path.join(DATA_PATH, filename)\n",
        "        try:\n",
        "            reader = PdfReader(file_path)\n",
        "            full_text = \"\\n\".join([p.extract_text() or \"\" for p in reader.pages])\n",
        "\n",
        "            if not full_text.strip():\n",
        "                print(f\"[ERROR] Skipping empty file: {filename}\")\n",
        "                continue\n",
        "\n",
        "            chunks = text_splitter.split_text(full_text)\n",
        "            e74_group = infer_e74_group(filename)\n",
        "\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                all_chunks.append(chunk)\n",
        "                all_metas.append({\n",
        "                    \"source_pdf\": filename,\n",
        "                    \"e74_group\": e74_group,\n",
        "                    \"chunk_index\": i\n",
        "                })\n",
        "                all_ids.append(f\"{filename}_chunk_{i}\")\n",
        "\n",
        "            print(f\"Processed: {filename}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Failed to process {filename}: {e}\")\n",
        "\n",
        "    # Upsert to DB\n",
        "    if all_chunks:\n",
        "        print(f\"Upserting {len(all_chunks)} chunks into '{COLLECTION_NAME}'...\")\n",
        "\n",
        "        batch_size = 5000\n",
        "        for i in range(0, len(all_chunks), batch_size):\n",
        "            end = min(i + batch_size, len(all_chunks))\n",
        "            collection.upsert(\n",
        "                documents=all_chunks[i:end],\n",
        "                metadatas=all_metas[i:end],\n",
        "                ids=all_ids[i:end]\n",
        "            )\n",
        "\n",
        "        print(f\"Vector Database populated. Total chunks: {collection.count()}\")\n",
        "    else:\n",
        "        print(\"[ERROR] No chunks found to insert.\")\n",
        "\n",
        "# Uncomment to run the build process. pdfs already processed and provided.\n",
        "build_vector_database()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "efc4b0cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efc4b0cb",
        "outputId": "f10e32ef-618b-4570-fc7b-f0f2082814b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KG Vector DB Target: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db\n",
            "Embedding Model: sentence-transformers/all-MiniLM-L6-v2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# KNOWLEDGE GRAPH EMBEDDING (SERIALIZATION)\n",
        "# Connects to Neo4j, serializes nodes and relationships into\n",
        "# natural language text (Structural Embedding), and stores them in a\n",
        "# separate ChromaDB collection with CRITICAL METADATA.\n",
        "#\n",
        "# CONFIGURATION NOTE:\n",
        "# This script is configured by default to use L2 (Euclidean) distance.\n",
        "# To use Cosine Similarity, uncomment the specific metadata configuration\n",
        "# in the 'Initialize Collection' section below.\n",
        "\n",
        "import os\n",
        "import chromadb\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# 1. CONFIGURATION & CREDENTIALS\n",
        "if 'CHROMA_PATH' not in locals():\n",
        "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
        "    CHROMA_PATH = os.path.join(ROOT_DIR, \"chroma_db\")\n",
        "\n",
        "load_dotenv()\n",
        "# Neo4j Credentials (Securely loaded from .env)\n",
        "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
        "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\", \"neo4j\")\n",
        "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
        "\n",
        "if not NEO4J_URI or not NEO4J_PASSWORD:\n",
        "    raise ValueError(\"[ERROR] Neo4j credentials missing in .env file.\")\n",
        "\n",
        "# Option A: Standard L2 Distance (Default)\n",
        "COLLECTION_NAME = \"kg_structural_rag\"\n",
        "\n",
        "# Option B: Cosine Similarity (Uncomment to use and comment other option)\n",
        "# COLLECTION_NAME = \"kg_structural_cosine\"\n",
        "\n",
        "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "print(f\"KG Vector DB Target: {CHROMA_PATH}\")\n",
        "print(f\"Embedding Model: {MODEL_NAME}\")\n",
        "\n",
        "\n",
        "# HELPER CLASSES AND FUNCTIONS\n",
        "\n",
        "class StructuralEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, model_name):\n",
        "        print(f\"Loading embedding model: {model_name}...\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        return self.model.encode(input, convert_to_numpy=True, normalize_embeddings=True).tolist()\n",
        "\n",
        "def safe_str(value):\n",
        "    if isinstance(value, list):\n",
        "        return \", \".join(str(v) for v in value)\n",
        "    return str(value)\n",
        "\n",
        "def get_node_name(node):\n",
        "    props = dict(node)\n",
        "    return props.get('name', props.get('title', node.element_id))\n",
        "\n",
        "# MAIN\n",
        "\n",
        "def generate_kg_embeddings():\n",
        "    # 1. Initialize Connections\n",
        "    print(f\"Connecting to Neo4j at {NEO4J_URI}...\")\n",
        "    try:\n",
        "        driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
        "        driver.verify_connectivity()\n",
        "        print(\"Connected to Neo4j.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Connection Failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # Initialize ChromaDB\n",
        "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
        "    embedding_func = StructuralEmbeddingFunction(MODEL_NAME)\n",
        "    try:\n",
        "        chroma_client.delete_collection(name=COLLECTION_NAME)\n",
        "        print(f\"Deleted existing collection: {COLLECTION_NAME}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Create Collection\n",
        "    # OPTION A: Standard Creation (L2 Distance) - ACTIVE\n",
        "    collection = chroma_client.create_collection(\n",
        "        name=COLLECTION_NAME,\n",
        "        embedding_function=embedding_func\n",
        "    )\n",
        "\n",
        "    # OPTION B: Cosine Similarity Configuration - INACTIVE\n",
        "    # Uncomment the block below to enable Cosine Similarity\n",
        "    # collection = chroma_client.create_collection(\n",
        "    #     name=COLLECTION_NAME,\n",
        "    #     embedding_function=embedding_func,\n",
        "    #     metadata={\"hnsw:space\": \"cosine\"} # Cosine Similarity\n",
        "    # )\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    documents = []\n",
        "    metadatas = []\n",
        "    ids = []\n",
        "\n",
        "    print(\"Fetching data from Neo4j and serializing...\")\n",
        "\n",
        "    with driver.session() as session:\n",
        "\n",
        "        # PHASE A: PROCESS NODES (Entity Serialization)\n",
        "        result_nodes = session.run(\"MATCH (n) RETURN n\")\n",
        "\n",
        "        for record in result_nodes:\n",
        "            node = record[\"n\"]\n",
        "            props = dict(node)\n",
        "            labels = list(node.labels)\n",
        "            label_str = labels[0] if labels else \"Unknown Entity\"\n",
        "            name = get_node_name(node)\n",
        "\n",
        "            # 1. Text Serialization\n",
        "            text_rep = f\"Entity: {name}. Type: {label_str}.\"\n",
        "            for key, value in props.items():\n",
        "                if key not in ['name', 'title', 'uri', 'element_id']:\n",
        "                    if value:\n",
        "                        text_rep += f\" {key.replace('_', ' ')}: {value}.\"\n",
        "\n",
        "            # 2. Metadata (CRITICAL FOR HYBRID LINKING)\n",
        "            meta = {\n",
        "                \"kind\": \"entity\",\n",
        "                \"entity_name\": safe_str(name),\n",
        "                \"labels\": safe_str(label_str),\n",
        "                \"source\": \"neo4j\"\n",
        "            }\n",
        "\n",
        "            documents.append(text_rep)\n",
        "            metadatas.append(meta)\n",
        "            ids.append(f\"node_{node.element_id}\")\n",
        "\n",
        "        # PHASE B: PROCESS RELATIONSHIPS (Structural Sentences)\n",
        "        result_rels = session.run(\"MATCH (n)-[r]->(m) RETURN n, r, m\")\n",
        "\n",
        "        for record in result_rels:\n",
        "            source = record[\"n\"]\n",
        "            rel = record[\"r\"]\n",
        "            target = record[\"m\"]\n",
        "\n",
        "            s_name = get_node_name(source)\n",
        "            t_name = get_node_name(target)\n",
        "\n",
        "            # 1. Text Serialization and metadata\n",
        "            text_rep = f\"{s_name} is connected to {t_name} via relation {rel.type}.\"\n",
        "            meta = {\n",
        "                \"kind\": \"relationship\",\n",
        "                \"source_node\": safe_str(s_name),\n",
        "                \"target_node\": safe_str(t_name),\n",
        "                \"relation_type\": safe_str(rel.type),\n",
        "                \"source\": \"neo4j\"\n",
        "            }\n",
        "\n",
        "            documents.append(text_rep)\n",
        "            metadatas.append(meta)\n",
        "            ids.append(f\"rel_{rel.element_id}\")\n",
        "\n",
        "    driver.close()\n",
        "\n",
        "    # Batch Ingestion\n",
        "    total_docs = len(documents)\n",
        "    if total_docs > 0:\n",
        "        print(f\"Ingesting {total_docs} vectors into ChromaDB...\")\n",
        "        batch_size = 500\n",
        "\n",
        "        for i in range(0, total_docs, batch_size):\n",
        "            end_idx = min(i + batch_size, total_docs)\n",
        "            collection.add(\n",
        "                documents=documents[i:end_idx],\n",
        "                metadatas=metadatas[i:end_idx],\n",
        "                ids=ids[i:end_idx]\n",
        "            )\n",
        "\n",
        "        print(\"Knowledge Graph Embedding Complete.\")\n",
        "        print(f\"Total Records in '{COLLECTION_NAME}': {collection.count()}\")\n",
        "    else:\n",
        "        print(\"[ERROR] No data found to process.\")\n",
        "\n",
        "# Uncomment to run the build process because kg embeddings are also provided in chroma db folder.\n",
        "#generate_kg_embeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9e6d1af3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595,
          "referenced_widgets": [
            "bc16bd0f2c6341b58f14fa1ced6e3229",
            "122976012af84294bd2cb96aec64dbaf",
            "ddce5c7f161e4e28bccb70d38333949a",
            "264aa5edf84c4de988743b4caecd3e08",
            "0fcf29ab584c43b2bdbcc64dc6f76fb6",
            "2c9e41431a104712913cbff0912dacf9",
            "ee55e62fc65945fb949a06cf69e72a8a",
            "bff3b624ca1f4d2ab2656931357ff215",
            "e845bc46d20446f58caedb60d9872fea",
            "452e08ca42b34b338fe6c0cd7f5a1468",
            "ec67560dc19b4d5e8bd71d1283cef457",
            "fd842d104add423891536d71e943d74e",
            "23030af97c76414ea81d29d56a16183b",
            "311f07edeff14d5493f472bdbe1b1ba6",
            "b9eb399f29904fc586ce69033d95ab03",
            "44932e2f20ef42709bbe39f5a71bca09",
            "7b0bd67424be43f39b660f9c86d84c7b",
            "5c0809324abe4b4b9e7e468b430b0bcf",
            "f708e83795b946769e7bcf77afca5751",
            "df10338c367345a0accec38964538c7e",
            "b37094be4bb246909aefd3cd2d7840c4",
            "c7ce3549820147a2bcc471c1bbcc6967",
            "84aa1d644ff345f7936e5ffa07df9ad8",
            "ef6d99e479dc47a28012652f7216eca9",
            "4d689e3cb5824161bb828987e58afa20",
            "b55a98e25e624022935fed0958c0dd13",
            "3f63547d79114620b5d2c123ea64f157",
            "6c128fcb598c45b8934a5b3a7a5b28ef",
            "242a608892a44ab2aa0a7943ee9cc271",
            "8f482b14a3a44a1e91918dc60d9e446e",
            "514cff062420407da0829b71b261bebd",
            "02a497c950d744a49600a5a452855f64",
            "27c8e15929f741deb06e5ac59d828295",
            "69f4152d203840fa8c420947a3a5b2b7",
            "40a6396382c149bdb9092c1bf052bb1b",
            "52604be871884a5e97c5c8d4051039d5",
            "1f9ffa67bc544c81943c4bcd40ad5c28",
            "480df5e46f464d34a0ac93806dca76bb",
            "18cabf26a2f449e09d941e0cc614bec5",
            "437c91f590e646fbbc0b3ade8f3ceddb",
            "5ae94a8fb97c4aed9244315484eed471",
            "b3740bbfc3a54d30a410d74494a677f0",
            "ff0a4743ffdd4033a88bac409f87d4d6",
            "9f0d2387e9ae45f08031b53be53fb371",
            "3587b39779a5492eb8e7e34b0aad570a",
            "927f5ad40410455aacb087d920cadeff",
            "b346eba156dc43c2a4f6dede2dcab9c2",
            "6a3c74df091348a7af987d6d4ae311f6",
            "03a7adc09eae4e9181201b0309912d58",
            "79ddbb1b29784a22ba5be8b469b7e6db",
            "b48bdbebf4574bc49327e72f64149101",
            "30c97683c4a84be8adf23c843ac2494d",
            "1ea8f2e5def54370816955e4508c4e0c",
            "e8b37df81e96456e938191843a1a0e3e",
            "cf2a022a94ce4056b8826903d1658cea",
            "d20bce8417b54fd59eb037641ed12faa",
            "fd7d0383a91948189eda394f89d43809",
            "ab814a46378c40219ebc458415c3737b",
            "44499c6834df4d9d8897b34d3f512515",
            "e94164a1ac1a4af7902e245e6b714879",
            "1a31130583ef4b719f5b89c84499149b",
            "403e8f03846b44c5a4bdd54e6253d9bf",
            "b179882a81cc47d78bed48a382cd4147",
            "a94a3a45260d409d977d549960fc9344",
            "c09169a14d1643a793b6f3fe03e96bf2",
            "17d2b80dd00041fda513b42414e55fa2",
            "5ce4bec10fed4d91aa9cfd306f5e9c65",
            "b4747a5920024a2d98eb11269c444133",
            "61901e2a48ef4a198ea39b9f63ac63d1",
            "e37576fa43604c428e3ebb93dba7b935",
            "2021f046204b4c3b98d67c7b4c3bacfc",
            "d4278ddfa04040489f0fc06b1a34012e",
            "1e6b02fd0d2b4696b742797e8d2df9fd",
            "0fbb50f3246a41f080d48de99d9f3031",
            "38447526d19048b99c678fc6f1c060e8",
            "243846901c9d4e268c6d98b33d08d525",
            "4f5c4b79657a4ea790af6b57b28e529a",
            "4baad629df85452eaf932e96ba57a82e",
            "7567154da5d948b1b22586608c5b3dbb",
            "16e76d6c248144d58b3acd0b555d82b2",
            "74dc8a2019ab42028eaab1ffeb53651d",
            "bc199b11217448c5bc9f313619335b42",
            "7417c0756bbb4af9a0c10dd345e3b81c",
            "538530aabe4e4a448dbc523e0abc8426",
            "8b3a5550181c48dea9312efc6b832518",
            "87224ea18a3e4da0aa45b68a32519f5f",
            "9f97340ca5ce42c19c8a8f560100b3c7",
            "3a557ffed664486e8ac11a2ceb8ce118",
            "8b4757eb22d64926930d09f1034b2acd",
            "cb0abe76b90c4a2881b3bfeb5a3ade54",
            "46dabfa73b3d40e1928b984aeb57e2e9",
            "8925a3b5ce6d4885935a02cd120a7103",
            "5520561f489c422a8658e3f5554a2424",
            "a16b889b29ad429bae94d16950177200",
            "32183108414f44cfacf6bd0ab1955ee7",
            "15753a09a64c4f159e68ad98006c329f",
            "26ed67cce9f249b3a5744e0f2419967b",
            "a8d68cdb59c04d658197f44887b5c1e2",
            "0065b13cd019423d96eb8c9dddf6a1db",
            "dbfee84d87784489b43aaedb806274cb",
            "cd7f814a13ca4391abbd2f3c960d7917",
            "b20895095b414362b1beb330181f6666",
            "015f8ad80bbe40cbb267ef34c4a5b8d6",
            "dd05065e0e1842028a6c941a49cbbcd9",
            "fd68e7b1d589428bbd0f8b2ba72900c3",
            "c3ce0fe5e25c4d5d8e5511e342195279",
            "72a3dc42c41c40ec9992b2f5e6d5d477",
            "68e828ec0f35450fb17138af4b81b43c",
            "0b70594094014250b0e0f08fbde54346",
            "35e3233a7fbc4fa69a56a63402cc43ff",
            "05880e74635443adadf8002f1375a4ac",
            "de5e5c9ba7634fd186a54c89dde49ee8",
            "390c76c6eb184e7a90f9d1519be46a60",
            "624c1e977eb44001be4196a087db9b58",
            "190d2c38c58b4dd2b6f91333ccd8f69d",
            "a878a6a98a42427c84cbd7793e815e94",
            "f5a20c735ee746eeae36101cd8a5e3c0",
            "b26832e0a56941679098fdba2e4a38e2",
            "2dc0d21495ac4c96ad19111f539c0e9b",
            "c17b1cc7540246cc9fa7f1907d73f983",
            "f83350154b5d4633972960436a8fac3c",
            "ee19003c03d14909832fe63d47317d98",
            "14e90ca43f4f4d76b6bd431d1168dfd7",
            "5d3650272d6045b096b0c2243df406d5",
            "a586f0f7b8f04359948c2828b62d0f81",
            "e0297f61fb6940ea81b03452320f3f4e",
            "dac2ee9233274f86af1027ff143ee1d6",
            "2a1eafa6c2004a09a6bd0fcb139103e8",
            "ee59d9a05c4548fca108a07eef6def27",
            "34a4386376db47e898532ca06b3a6a78",
            "addc5099d7c54dfa8e609eb6a8d61bfc",
            "a345d11cd1da441b8bf38db685590bb5"
          ]
        },
        "id": "9e6d1af3",
        "outputId": "c536cdfe-d801-4ee4-fc8c-715e569d963d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Successfully authenticated with Hugging Face.\n",
            "GPU Detected: NVIDIA A100-SXM4-40GB\n",
            "Loading model: meta-llama/Meta-Llama-3.1-8B-Instruct...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc16bd0f2c6341b58f14fa1ced6e3229",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd842d104add423891536d71e943d74e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84aa1d644ff345f7936e5ffa07df9ad8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69f4152d203840fa8c420947a3a5b2b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3587b39779a5492eb8e7e34b0aad570a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d20bce8417b54fd59eb037641ed12faa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ce4bec10fed4d91aa9cfd306f5e9c65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4baad629df85452eaf932e96ba57a82e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b4757eb22d64926930d09f1034b2acd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbfee84d87784489b43aaedb806274cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05880e74635443adadf8002f1375a4ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee19003c03d14909832fe63d47317d98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully.\n",
            "Text generation pipeline initialized (Greedy Search Mode).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# LOAD LLM (Meta-Llama-3.1-8B-Instruct)\n",
        "# Initializes the Llama-3.1-8B-Instruct model using 4-bit\n",
        "# quantization for memory efficiency. Authenticates using the environment\n",
        "# variable. Configured for GREEDY SEARCH (Temp 0) for RAG.\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from dotenv import load_dotenv\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "from huggingface_hub import login\n",
        "\n",
        "# AUTHENTICATION & ENVIRONMENT SETUP\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "\n",
        "if not HF_TOKEN:\n",
        "    raise ValueError(\"[ERROR] HUGGINGFACEHUB_API_TOKEN not found in environment variables.\")\n",
        "\n",
        "try:\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\" Successfully authenticated with Hugging Face.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] Authentication failed: {e}\")\n",
        "    raise e\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"[ERROR] GPU not detected. CUDA is required.\")\n",
        "\n",
        "print(f\"GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# QUANTIZATION CONFIGURATION (4-bit)\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "\n",
        "# MODEL & TOKENIZER\n",
        "\n",
        "print(f\"Loading model: {model_id}...\")\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map={\"\": 0},\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        low_cpu_mem_usage=True,\n",
        "        token=HF_TOKEN\n",
        "    )\n",
        "    print(\"Model loaded successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] Failed to load model: {e}\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "# PIPELINE INITIALIZATION (Deterministic)\n",
        "\n",
        "text_generation_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=600,\n",
        "    return_full_text=False,\n",
        "    do_sample=False  # ENABLE GREEDY SEARCH (Temperature = 0)\n",
        ")\n",
        "\n",
        "print(\"Text generation pipeline initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e5122384",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5122384",
        "outputId": "d955c1e1-b97f-4931-a9b3-2a586d294ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to Vector DB at: /content/Hybrid-RAG-for-Sparsed-Municipal-Environments-DataSource-master/chroma_db\n",
            "Connecting to Graph DB at: neo4j+s://be24de9e.databases.neo4j.io\n",
            "PDF Collection: municipal_pdfs_rag\n",
            "KG Collection:  kg_structural_rag\n",
            "Distance Threshold: 1.6\n",
            "All Databases Connected. Narrative Flow Active.\n",
            "\n",
            "================================================================================\n",
            "STARTING HYBRID RAG EXECUTION CYCLE\n",
            "================================================================================\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[QUERY] Q1: Which groups provide workshops or tools that support woodworking activities?\n",
            "--------------------------------------------------------------------------------\n",
            "Search Pattern: [woodworking|workshop|tool|activity]\n",
            "Active KG Search Terms: ['woodworking', 'activity']\n",
            "Graph Found: 9 organizations with relevant inventory.\n",
            "\n",
            "Final Answer:\n",
            "Holzwerkstatt Gostenhof e.V. provides a comprehensive woodworking workshop environment, offering various tools and machinery for its members and visitors to work on their non-commercial projects. The workshop is well-equipped and has been maintained with a focus on keeping membership and usage fees low. Members can access a range of woodworking tools, including the Altendorf WA6 (Panel Saw), Festool TS 75 EbQ (Plunge Saw), and others. The workshop is open to members and visitors, with a usage fee of 4 euros per evening.\n",
            "\n",
            "KunstKultur Quartier Werkstatten offers a woodworking workshop that is open to the public, providing a space for DIY enthusiasts, hobbyists, and artists to work on their projects. The workshop is well-equipped with various tools, including a Holzwerkstatt (Woodworking Workshop) and a Felco Klappsäge (Saw). The workshop is open to the public, with a usage fee of 4 euros per evening.\n",
            "\n",
            "FabLab Nürnberg also provides a woodworking workshop, offering a range of tools and machinery for its members and visitors. The workshop is open to the public, with a focus on providing a space for people to work on their projects, including woodworking activities. The workshop is equipped with tools such as the Bernardo Hobby 350 VDM (Drehbank) and the Parkside PSBS 240 B2 (Schleifgerät).\n",
            "\n",
            "TH Nürnberg's OHMlab provides a makerspace that includes a woodworking workshop, offering a range of tools and machinery for its students. The workshop is restricted to TH Nürnberg students, providing a space for them to work on their projects, including woodworking activities.\n",
            "\n",
            "Leonardo Zentrum provides a makerspace and workshop that is restricted to Hochschule für Musik und Akademie der bildenden Künste and TH Nürnberg students, offering a range of tools and machinery for woodworking activities.\n",
            "\n",
            "FAU FabLab provides a makerspace that includes a woodworking workshop, offering a range of tools and machinery for its members and visitors. The workshop is open to the public, with a focus on providing a space for people to work on their projects, including woodworking activities.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[QUERY] Q2: Which publicly accessible spaces are suitable for hosting small public meetings?\n",
            "--------------------------------------------------------------------------------\n",
            "Search Pattern: [meeting|space|venue|room|hall|lobby|lobby_area|public_space|event]\n",
            "Active KG Search Terms: ['meeting', 'venue', 'room', 'hall', 'lobby', 'lobby_area', 'event']\n",
            "Graph Found: 3 organizations with relevant inventory.\n",
            "\n",
            "Final Answer:\n",
            "The Heizhaus Nürnberg provides the Event Hall, a community and event space suitable for various activities, including public meetings. The KLARA offers the KLARA Open, a civic participation and event space that is also open to the public for meetings, workshops, and events. The KOLEO provides the Lern und Kreativwerkstatt, a co-working and creative workshop that can be used for meetings and creative workshops.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[QUERY] Q3: Which places support media production projects (video/audio)?\n",
            "--------------------------------------------------------------------------------\n",
            "Search Pattern: [production|studio|recording|facility|broadcast|equipment|audio|video|post_production]\n",
            "Active KG Search Terms: ['production', 'studio', 'recording', 'broadcast', 'audio', 'video', 'post_production']\n",
            "Graph Found: 2 organizations with relevant inventory.\n",
            "\n",
            "Final Answer:\n",
            "The Diversity Media Workspace provided by Diversity Media is a suitable location for media production projects. This facility is specifically designed for media production and offers a variety of equipment for audiovisual content creation. It is open to the public, allowing individuals to utilize the recording and editing equipment for their projects.\n",
            "\n",
            "The Studio für Audio und Videoproduktion, also provided by Diversity Media, is another excellent option for media production. This studio is equipped for post-production, music production, and audio research, making it an ideal space for various media projects. It is connected to the Diversity Media Facility and is suitable for tasks such as editing, mixing, and mastering.\n",
            "\n",
            "The MIRACL Sound Lab provided by Leonardo Zentrum is also a suitable location for media production, particularly for audio-related projects. It is restricted to students of Hochschule für Musik und Akademie der bildenden Künste and TH Nürnberg, but it is well-suited for tasks such as tonaufnahmen, post-production, and audio research.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[QUERY] Q4: Which municipal facilities are suitable for a 'Repair' or 'Maintenance' project ?\n",
            "--------------------------------------------------------------------------------\n",
            "Search Pattern: [repair|maintenance|facility|municipal|maintenance_project|repair_project]\n",
            "Active KG Search Terms: ['repair', 'maintenance', 'facility', 'municipal', 'maintenance_project', 'repair_project']\n",
            "Graph Found: 2 organizations with relevant inventory.\n",
            "\n",
            "Final Answer:\n",
            "The FAU FabLab provides a Repair and Maintenance Workshop, FAU Fahrradreparatur, which is open to the public. This facility is suitable for repair and maintenance projects. The KunstKultur Quartier Werkstatten also offers a Fahrradwerkstatt, a Repair and Maintenance Workshop, with public access. This workshop is also available for repair and maintenance projects.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[QUERY] Q5: Which facilities or groups provide 3D printers or 3D printing workshops?\n",
            "--------------------------------------------------------------------------------\n",
            "Search Pattern: [3d_printer|3d_printing|workshop|facility|group|lab|maker]\n",
            "Active KG Search Terms: ['3d_printer', '3d_printing', 'group', 'maker']\n",
            "Graph Found: 5 organizations with relevant inventory.\n",
            "\n",
            "Final Answer:\n",
            "The TH Nürnberg group, located at OHMlab, provides several 3D printers, including the Creality CR20pro, FLSUN Q5, and Prusa MINI. However, the access to these facilities is restricted to TH Nürnberg students.\n",
            "\n",
            "The FAU FabLab offers a variety of 3D printers, such as the BambuLab Printer and Ultimaker 2+, with public access. They also provide a makerspace for prototyping and fabrication.\n",
            "\n",
            "The FabLab Nürnberg provides 3D printers like the Artillery Sidewinder X1 and Prusa i3MK2, with public access. Their makerspace, FabLab Nürnberg Workspace, is also available for use.\n",
            "\n",
            "The Leonardo Zentrum, located at the same location, offers a makerspace and workshop for prototyping and fabrication, including 3D printing, CNC, and laser cutting. This facility is restricted to Hochschule für Musik und Akademie der bildenden Künste and TH Nürnberg students.\n",
            "\n",
            "The FabLab Nüland provides a makerspace, FabLab Nüland Werkstatt, with access only for members, and a 3D printer, Formlabs Form 1+.\n",
            "\n",
            "================================================================================\n",
            "EXECUTION COMPLETE\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# HYBRID RAG PIPELINE\n",
        "\n",
        "# DESCRIPTION: The core execution engine of the project. It integrates:\n",
        "# 1. LLM-Based Query Understanding, Intent Analysis & Keyword Extraction\n",
        "# 2. Semantic Vector Retrieval (ChromaDB - PDF & KG)\n",
        "# 3. Structured Graph Retrieval (Neo4j Cypher)\n",
        "# 4. Context-Aware Response Generation (Llama 3.1)\n",
        "#\n",
        "# CONFIGURATION NOTE:\n",
        "# Default settings use L2 Distance. To switch to Cosine Similarity,\n",
        "# uncomment the respective collection names AND the threshold values below.\n",
        "\n",
        "import torch\n",
        "import gc\n",
        "import re\n",
        "import os\n",
        "from neo4j import GraphDatabase\n",
        "import chromadb\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "# 1. CONFIGURATION & DATABASE INITIALIZATION\n",
        "# Define Paths\n",
        "if 'CHROMA_PATH' not in locals():\n",
        "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
        "    CHROMA_PATH = os.path.join(ROOT_DIR, \"chroma_db\")\n",
        "\n",
        "# Define Credentials (from .env file)\n",
        "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
        "NEO4J_AUTH = (os.getenv(\"NEO4J_USERNAME\", \"neo4j\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
        "\n",
        "if not NEO4J_URI or not NEO4J_AUTH[1]:\n",
        "    raise ValueError(\"[ERROR] Neo4j credentials missing in environment variables.\")\n",
        "\n",
        "# --- METRIC & COLLECTION CONFIGURATION (L2 vs COSINE SWITCH) ---\n",
        "\n",
        "# OPTION A: L2 Distance (Default - Euclidean)\n",
        "# Lower score is better. Range usually [0, 2] for normalized vectors.\n",
        "PDF_COLLECTION_NAME = \"municipal_pdfs_rag\"\n",
        "KG_COLLECTION_NAME = \"kg_structural_rag\"\n",
        "SIMILARITY_THRESHOLD = 1.6  # High tolerance for L2\n",
        "\n",
        "# OPTION B: Cosine Similarity (Uncomment to use)\n",
        "# Distance = 1 - CosineSimilarity. Lower is better. Range [0, 1].\n",
        "# PDF_COLLECTION_NAME = \"municipal_pdfs_cosine\"\n",
        "# KG_COLLECTION_NAME = \"kg_structural_cosine\"\n",
        "# SIMILARITY_THRESHOLD = 0.4  # Stricter tolerance for Cosine Distance (approx 0.6 similarity)\n",
        "\n",
        "print(f\"Connecting to Vector DB at: {CHROMA_PATH}\")\n",
        "print(f\"Connecting to Graph DB at: {NEO4J_URI}\")\n",
        "print(f\"PDF Collection: {PDF_COLLECTION_NAME}\")\n",
        "print(f\"KG Collection:  {KG_COLLECTION_NAME}\")\n",
        "print(f\"Distance Threshold: {SIMILARITY_THRESHOLD}\")\n",
        "\n",
        "class NormalizedEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, model_name):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        # Normalizing queries\n",
        "        return self.model.encode(input, convert_to_numpy=True, normalize_embeddings=True).tolist()\n",
        "\n",
        "try:\n",
        "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
        "\n",
        "    # [DEĞİŞTİ] Define Embedding Functions(normalized)\n",
        "    ef_pdf = NormalizedEmbeddingFunction(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "    ef_kg = NormalizedEmbeddingFunction(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Initialize Collections\n",
        "    pdf_collection = chroma_client.get_collection(name=PDF_COLLECTION_NAME, embedding_function=ef_pdf)\n",
        "    kg_vec_collection = chroma_client.get_collection(name=KG_COLLECTION_NAME, embedding_function=ef_kg)\n",
        "\n",
        "    driver = GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH)\n",
        "    driver.verify_connectivity()\n",
        "    print(\"All Databases Connected. Narrative Flow Active.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] Database Connection Failed: {e}\")\n",
        "\n",
        "\n",
        "# Cleaning\n",
        "def clean_ontology_text(text):\n",
        "    if not text: return \"\"\n",
        "    text = re.sub(r'^[A-Z]\\d+_', '', text)\n",
        "    text = re.sub(r'-\\d+$', '', text)\n",
        "    text = text.replace('_', ' ')\n",
        "    text = re.sub(r'(?i)\\s(Facility|Area|Place|Object|Model|type|Group)$', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# DYNAMIC KEYWORD GENERATOR (LLM-BASED INTENT ANALYSIS WITH FEW SHOT LEARNING)\n",
        "\n",
        "def generate_dynamic_search_pattern(question: str):\n",
        "\n",
        "    #Uses the LLM to analyze user intent and extract technical keywords\n",
        "    #from the user question for targeted Graph database querying.\n",
        "\n",
        "    extraction_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "    You are a search engine backend. Extract core technical keywords in singular form.\n",
        "    Return ONLY keywords separated by pipes (|). Do not include any other text.\n",
        "    STRICT RULE: Avoid generic words like 'access', 'rules', 'organization', 'policy', 'facility'.\n",
        "\n",
        "    Q: Where is the nearest room with an MRI scanner?\n",
        "    K: mri_scanner|radiology|room\n",
        "\n",
        "    Q: I need a large venue for a corporate surgery simulation.\n",
        "    K: surgery|simulation|unit|medical|theatre|hospital\n",
        "\n",
        "    Q: Which airlock is available for EVA suits?\n",
        "    K: airlock|eva_suit|pressure_hatch\n",
        "\n",
        "    Q: I am looking for a specialized hangar for satellite maintenance.\n",
        "    K: satellite_maintenance|hangar|space|engineering|data\n",
        "\n",
        "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    Q: {question}\n",
        "    K:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
        "\n",
        "    try:\n",
        "        output = text_generation_pipeline(extraction_prompt, max_new_tokens=20, do_sample=False)[0]['generated_text']\n",
        "        raw = output.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].strip().lower()\n",
        "        clean_words = re.sub(r\"[^\\w\\|]\", \" \", raw).split()\n",
        "        forbidden = [\n",
        "            \"facility\", \"facilities\", \"group\", \"groups\", \"workshop\", \"workshops\",\n",
        "            \"based\", \"find\", \"looking\", \"where\", \"which\"\n",
        "        ]\n",
        "\n",
        "        keywords = [w for w in clean_words if len(w) > 2 and w not in forbidden]\n",
        "\n",
        "        return \"|\".join(keywords[:5])\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Keyword extraction failed: {e}\")\n",
        "        return \"facility|equipment\"\n",
        "\n",
        "# MULTI-SOURCE VECTOR RETRIEVAL\n",
        "\n",
        "def retrieve_all_embeddings(question, top_k=5):\n",
        "\n",
        "    context_data = {\"pdfs\": [], \"kg_vectors\": []}\n",
        "\n",
        "    try:\n",
        "        # PDF COLLECTION QUERY\n",
        "        res_pdf = pdf_collection.query(\n",
        "            query_texts=[question],\n",
        "            n_results=top_k,\n",
        "            include=['documents', 'metadatas', 'distances']\n",
        "        )\n",
        "\n",
        "        if res_pdf['documents']:\n",
        "            for doc, meta, dist in zip(res_pdf['documents'][0], res_pdf['metadatas'][0], res_pdf['distances'][0]):\n",
        "                if dist > SIMILARITY_THRESHOLD: continue\n",
        "                group = meta.get('e74_group', 'General Doc')\n",
        "                context_data[\"pdfs\"].append(f\"[{group}]: {doc.strip()}\")\n",
        "\n",
        "        # KG COLLECTION QUERY\n",
        "        res_kg = kg_vec_collection.query(\n",
        "            query_texts=[question],\n",
        "            n_results=top_k,\n",
        "            include=['documents', 'metadatas', 'distances']\n",
        "        )\n",
        "\n",
        "        if res_kg['documents']:\n",
        "            for doc, dist in zip(res_kg['documents'][0], res_kg['distances'][0]):\n",
        "                if dist > SIMILARITY_THRESHOLD: continue\n",
        "                context_data[\"kg_vectors\"].append(f\"{doc.strip()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Vector Retrieval Error: {e}\")\n",
        "        pass\n",
        "\n",
        "    return context_data\n",
        "\n",
        "\n",
        "# SEMANTIC CYPHER SEARCH\n",
        "\n",
        "def fetch_kg_facts(regex_pattern: str):\n",
        "    \"\"\"\n",
        "    Executes a complex Cypher query to retrieve structured facts based on\n",
        "    semantic hierarchy and keyword matching.\n",
        "    \"\"\"\n",
        "    raw_terms = [t.strip().lower() for t in regex_pattern.split('|') if len(t) > 2]\n",
        "\n",
        "    # Specificity Logic\n",
        "    specific_indicators = [\n",
        "        \"wood\", \"woodworking\", \"carpentry\", \"lathe\", \"saw\", \"drill\", \"workshop\",\n",
        "        \"garden\", \"gardening\", \"agriculture\", \"nature\", \"outdoor\", \"farm\",\n",
        "        \"textile\", \"sew\", \"tailor\",\n",
        "        \"3d_Printer\", \"3d\", \"laser\", \"cnc\", \"metal\", \"milling\", \"fabrication\",\n",
        "        \"audio\", \"video\", \"media\", \"sound\", \"lab\", \"studio\", \"record\", \"acoustic\", \"production\",\n",
        "        \"meeting\", \"conference\", \"seminar\", \"event\", \"hall\", \"social\", \"civic\",\n",
        "        \"community\", \"gathering\", \"room\", \"venue\", \"lecture\", \"exhibition\",\n",
        "        \"gallery\", \"stage\", \"performance\"\n",
        "    ]\n",
        "\n",
        "    generic_terms = [\"tool\", \"equipment\", \"machine\", \"device\", \"facility\", \"workshop\", \"space\", \"lab\"]\n",
        "\n",
        "    is_specific = any(s in term for term in raw_terms for s in specific_indicators)\n",
        "\n",
        "    if is_specific:\n",
        "        search_terms = [t for t in raw_terms if not any(g in t for g in generic_terms)]\n",
        "        if not search_terms: search_terms = raw_terms\n",
        "    else:\n",
        "        search_terms = raw_terms\n",
        "\n",
        "    print(f\"Active KG Search Terms: {search_terms}\")\n",
        "\n",
        "    access_logic = \"\"\"\n",
        "    OPTIONAL MATCH (entity)-[:P55_has_current_location]->(direct_loc)\n",
        "    OPTIONAL MATCH (owner)-[:P52i_is_current_owner_of]->(fac:E53_Place)\n",
        "    WITH entity, owner, final_type, coalesce(direct_loc.name, fac.name, \"General Facility\") AS LocName\n",
        "    OPTIONAL MATCH (restriction:E30_Right)-[:P105_right_held_by]->(owner)\n",
        "    WITH entity, owner, final_type, LocName,\n",
        "          coalesce(restriction.name, \"Public Access\") AS AccessStatus\n",
        "    \"\"\"\n",
        "\n",
        "    return_part = \"\"\"\n",
        "    RETURN owner.name AS Org,\n",
        "           LocName AS Loc,\n",
        "           entity.name AS Item,\n",
        "           coalesce(final_type.name, \"Equipment\") AS Cat,\n",
        "           coalesce(entity.P3_has_note, \"\") AS Note,\n",
        "           AccessStatus AS Access\n",
        "    \"\"\"\n",
        "\n",
        "    cypher = f\"\"\"\n",
        "    // BRANCH 1: HIERARCHY CHAIN\n",
        "    MATCH (t:E55_Type)\n",
        "    WHERE any(word IN $terms WHERE toLower(t.name) CONTAINS word)\n",
        "    MATCH (child_type:E55_Type)-[:P127_has_broader_term*0..2]->(t)\n",
        "    MATCH (entity)-[:P2_has_type]->(final_type)\n",
        "    WHERE final_type = child_type\n",
        "    AND (entity:`E22_Human-Made_Object` OR entity:`E24_Physical_Human-Made_Thing` OR entity:`E25_Human-Made_Feature`)\n",
        "    MATCH (owner:E74_Group)-[:P52i_is_current_owner_of]->(entity)\n",
        "    {access_logic}\n",
        "    {return_part}\n",
        "\n",
        "    UNION\n",
        "\n",
        "    // BRANCH 2: MODEL CHAIN\n",
        "    MATCH (t:E55_Type)\n",
        "    WHERE any(word IN $terms WHERE toLower(t.name) CONTAINS word)\n",
        "    MATCH (child_type:E55_Type)-[:P127_has_broader_term*0..2]->(t)\n",
        "    MATCH (entity)-[:P2_has_type]->(:E99_Product_Type)-[:P2_has_type]->(final_type)\n",
        "    WHERE final_type = child_type\n",
        "    MATCH (owner:E74_Group)-[:P52i_is_current_owner_of]->(entity)\n",
        "    {access_logic}\n",
        "    {return_part}\n",
        "\n",
        "    UNION\n",
        "\n",
        "    // BRANCH 3: TEXT CHAIN\n",
        "    MATCH (entity)\n",
        "    WHERE (any(word IN $terms WHERE toLower(entity.name) CONTAINS word)\n",
        "        OR any(word IN $terms WHERE toLower(entity.P3_has_note) CONTAINS word))\n",
        "    AND (entity:`E22_Human-Made_Object` OR entity:`E24_Physical_Human-Made_Thing` OR entity:`E25_Human-Made_Feature`)\n",
        "    OPTIONAL MATCH (entity)-[:P2_has_type*1..2]->(final_type:E55_Type)\n",
        "    MATCH (owner:E74_Group)-[:P52i_is_current_owner_of]->(entity)\n",
        "    {access_logic}\n",
        "    {return_part}\n",
        "    \"\"\"\n",
        "\n",
        "    full_query = f\"\"\"\n",
        "    CALL () {{\n",
        "        {cypher}\n",
        "    }}\n",
        "    WITH Org, Loc, Access, Item, Cat, Note\n",
        "    WITH Org, Loc, replace(Access, '_', ' ') AS CleanAccess, Item, replace(Cat, '_', ' ') AS CleanCat, Note\n",
        "\n",
        "    ORDER BY Item\n",
        "    RETURN Org, Loc, CleanAccess, collect(distinct {{Item: Item, Category: CleanCat, Note: Note}}) as Inventory\n",
        "    ORDER BY size(Inventory) DESC\n",
        "    LIMIT 20\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "    try:\n",
        "        with driver.session() as session:\n",
        "            r = session.run(full_query, terms=search_terms)\n",
        "            for row in r:\n",
        "                org = clean_ontology_text(row[\"Org\"])\n",
        "                loc = clean_ontology_text(row[\"Loc\"])\n",
        "                access = row[\"CleanAccess\"]\n",
        "\n",
        "                items_with_type = []\n",
        "                for item in row[\"Inventory\"]:\n",
        "                    i_name = clean_ontology_text(item['Item'])\n",
        "                    i_cat = clean_ontology_text(item['Category'])\n",
        "\n",
        "                    if i_cat.lower() in i_name.lower():\n",
        "                        items_with_type.append(i_name)\n",
        "                    else:\n",
        "                        items_with_type.append(f\"{i_name} (type: {i_cat})\")\n",
        "\n",
        "                resources_str = \", \".join(items_with_type)\n",
        "\n",
        "                clean_org = org.lower().replace(\" \", \"\")\n",
        "                clean_loc = loc.lower().replace(\" \", \"\")\n",
        "\n",
        "                if clean_loc in clean_org or clean_org in clean_loc:\n",
        "                    segment = f\"The group '{org}' provides the following: {resources_str}. Access rule: {access}.\"\n",
        "                else:\n",
        "                    segment = f\"The group '{org}' (located at {loc}) provides the following: {resources_str}. Access rule: {access}.\"\n",
        "                results.append(segment)\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Neo4j Query Failed: {e}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# RESPONSE GENERATION (CONTEXT-AWARE NARRATIVE)\n",
        "\n",
        "def generate_full_response(question, pdf_context, kg_vec_context, kg_facts):\n",
        "\n",
        "    if not pdf_context and not kg_vec_context and not kg_facts:\n",
        "        return \"Based on the available municipal data, no relevant facilities or workshops were found matching your specific request.\"\n",
        "\n",
        "    all_narrative = \"\\n\".join(pdf_context) + \"\\n\" + \"\\n\".join(kg_vec_context)\n",
        "    kg_fact_text = \"\\n\".join(kg_facts) if kg_facts else \"NO DIRECT INVENTORY MATCH FOUND IN KG.\"\n",
        "\n",
        "    system_instruction = \"\"\"You are the Nuremberg Municipal Resource Expert. Answer using the provided Context Sources.\n",
        "\n",
        "YOUR TASK: Analyze the user's INTENT and map it to the Inventory using the following GENERAL LOGIC RULES.\n",
        "\n",
        "    1. EVIDENCE VERIFICATION (The \"Specificity\" Rule):\n",
        "       - IF the user asks for a SPECIFIC TOOL or OBJECT: You must find an EXPLICIT mention of that exact object in the source text.\n",
        "       - A general facility category (e.g., \"Workshop\", \"Makerspace\") is NOT sufficient proof that they possess a specific device.\n",
        "       - CONSEQUENCE: If the text does not explicitly list the requested item, DISCARD THE FACILITY immediately. Do not mention it.\n",
        "\n",
        "    2. FUNCTIONAL COMPATIBILITY (The \"Context\" Rule):\n",
        "       - Analyze the nature of the requested activity (e.g., Social Gathering vs. Industrial Production).\n",
        "       - Ensure the recommended facility's primary environment matches this activity.\n",
        "       - EXCLUSION: Do not recommend noise-heavy or industrial environments for social/quiet activities unless they explicitly list a dedicated event space.\n",
        "\n",
        "    3. RELEVANCE FILTERING (The \"Focus\" Rule):\n",
        "       - IF the user asks for a specific category (e.g., \"Avionics or Flight Instruments\"), ONLY mention items within that technical domain.\n",
        "       - DO NOT mention unrelated subsystems such as landing gear, engine components, or cabin interior, even if they are located in the same hangar or facility.\n",
        "       - SILENTLY OMIT all unrelated inventory parts to maintain strict focus on the user's intent.\n",
        "       - If a facility offers a diverse inventory, ONLY extract and mention the items relevant to the user's current specific question.\n",
        "       - SILENTLY OMIT unrelated departments or tools to keep the answer focused.\n",
        "       - NEVER mention about additional information about unrelated fields. If user asks something about flight, you should only strict to the question.\n",
        "\n",
        "    4. NO LISTS:\n",
        "       - Do NOT use bullet points. Write in continuous, flowing, natural paragraphs.\n",
        "\n",
        "    5. NO REDUNDANCY:\n",
        "       - Avoid repetitive phrasing regarding locations.\n",
        "       - If the Organization Name is identical or highly similar to the Location Name, do not state the location separately.\n",
        "\n",
        "    6. ENTITY CONSOLIDATION:\n",
        "       - If the source data contains multiple segments referring to the same organization, SYNTHESIZE them into a single, coherent description.\n",
        "       - Do not write separate sentences or paragraphs for the same entity.\n",
        "\n",
        "    7. ACCESS TRANSLATION:\n",
        "       - Convert raw access tags into natural language statements (e.g., \"It is open to the public\" instead of \"Public Access\").\n",
        "\n",
        "    8. NO RAW METADATA:\n",
        "       - Identify and remove internal tags (e.g., [Type: ...], [Model: ...]).\n",
        "       - Incorporate the information naturally into the sentence structure without using brackets.\n",
        "\n",
        "    9. MANDATORY OWNERSHIP STRUCTURE:\n",
        "       - You must ALWAYS present the data in a Parent-Child hierarchy.\n",
        "       - Every specific location, facility, or room must be explicitly linked to its owning Organization or Group.\n",
        "       - NEVER mention a sub-facility in isolation.\n",
        "       - Preferred phrasing: \"[Organization Name]'s [Facility Name]\" or \"The [Facility Name] provided by [Organization Name]\".\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "    === SOURCE 1: VERIFIED KG INVENTORY ===\n",
        "    {kg_fact_text}\n",
        "\n",
        "    === SOURCE 2: CONTEXT (PDFs & Vectors) ===\n",
        "    {all_narrative}\n",
        "\n",
        "    === USER QUESTION ===\n",
        "    {question}\n",
        "\n",
        "    Answer in flowing paragraphs based on the RULES. DO NOT use single or double quotation marks around organization names, facilities, or tools. Treat them as proper nouns within the flow. NO BULLET POINTS. NO SUMMARIES.\"\"\"\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_instruction}, {\"role\": \"user\", \"content\": user_prompt}]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    output = text_generation_pipeline(prompt, max_new_tokens=1000)[0]['generated_text']\n",
        "\n",
        "    return output.split(\"<|end_header_id|>\")[-1].replace(\"<|eot_id|>\", \"\").strip()\n",
        "\n",
        "\n",
        "# MAIN EXECUTION LOOP\n",
        "\n",
        "questions = {\n",
        "    \"Q1\": \"Which groups provide workshops or tools that support woodworking activities?\",\n",
        "    \"Q2\": \"Which publicly accessible spaces are suitable for hosting small public meetings?\",\n",
        "    \"Q3\": \"Which places support media production projects (video/audio)?\",\n",
        "    \"Q4\": \"Which municipal facilities are suitable for a 'Repair' or 'Maintenance' project ?\",\n",
        "    \"Q5\": \"Which facilities or groups provide 3D printers or 3D printing workshops?\"\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING HYBRID RAG EXECUTION CYCLE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for q_id, q_text in questions.items():\n",
        "    print(f\"\\n{'-'*80}\")\n",
        "    print(f\"[QUERY] {q_id}: {q_text}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # 1. Intent Analysis & Keyword Extraction\n",
        "    regex = generate_dynamic_search_pattern(q_text)\n",
        "    print(f\"Search Pattern: [{regex}]\")\n",
        "\n",
        "    # 2. Vector Retrieval\n",
        "    embeddings_data = retrieve_all_embeddings(q_text, top_k=5)\n",
        "\n",
        "    # 3. Graph Retrieval\n",
        "    structured_facts = fetch_kg_facts(regex)\n",
        "    print(f\"Graph Found: {len(structured_facts)} organizations with relevant inventory.\")\n",
        "\n",
        "    # 4. Generation\n",
        "    answer = generate_full_response(\n",
        "        q_text,\n",
        "        embeddings_data['pdfs'],\n",
        "        embeddings_data['kg_vectors'],\n",
        "        structured_facts\n",
        "    )\n",
        "\n",
        "    print(f\"\\nFinal Answer:\\n{answer}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXECUTION COMPLETE\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
